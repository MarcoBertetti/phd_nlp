{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, multilabel_confusion_matrix\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "events = pd.read_parquet(\"../data/gdelt/events/6_final/events_dataset_v2.parquet\")\n",
    "events = events[events['period'] <= '202406']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(events.index))\n",
    "print(events.columns)\n",
    "events.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting Configuration\n",
    "# ============================\n",
    "# Set the forecast horizon: predict CS_score N periods ahead\n",
    "# Options: 1 (nowcasting), 2, 3, or 4 (forecasting)\n",
    "# Literature shows GDELT features are more valuable for forecasting (2-4 periods ahead)\n",
    "# because baseline (previous_CS) becomes less powerful with longer horizons\n",
    "\n",
    "FORECAST_HORIZON = 3  # Predict 3 periods ahead (can be changed to 2 or 4)\n",
    "\n",
    "print(f\"=== Forecasting Configuration ===\")\n",
    "print(f\"Forecast Horizon: {FORECAST_HORIZON} period(s) ahead\")\n",
    "if FORECAST_HORIZON == 1:\n",
    "    print(\"Mode: NOWCASTING (predicting next period)\")\n",
    "else:\n",
    "    print(f\"Mode: FORECASTING (predicting {FORECAST_HORIZON} periods ahead)\")\n",
    "print(f\"\\nWhy forecasting helps GDELT features:\")\n",
    "print(f\"  - Baseline 'previous_CS' becomes less predictive ({FORECAST_HORIZON} periods old)\")\n",
    "print(f\"  - GDELT temporal patterns can capture early warning signals\")\n",
    "print(f\"  - More realistic for early warning systems\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = events.copy()\n",
    "print(f\"Total rows: {len(df.index)}\")\n",
    "print(f\"Period range: {min(df['period'])} to {max(df['period'])}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Drop rows where ADMIN0 is missing\n",
    "mask_missing = df['ADMIN0'].isna() | (df['ADMIN0'] == 'None') | (df['ADMIN0'] == None)\n",
    "if mask_missing.sum() > 0:\n",
    "    print(f\"Dropping {mask_missing.sum()} rows with ADMIN0=None\")\n",
    "    df = df[~mask_missing].copy()\n",
    "\n",
    "print(f\"Final rows: {len(df)}\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"ADMIN0\", \"ADMIN1\", \"ADMIN2\", \"period\"]\n",
    "\n",
    "def check_duplicates(df, name):\n",
    "    dupes = (\n",
    "        df\n",
    "        .groupby(key_cols)\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "        .query(\"n > 1\")\n",
    "    )\n",
    "    print(f\"{name}: {len(dupes)} duplicated keys\")\n",
    "    return dupes\n",
    "\n",
    "dupes = check_duplicates(df, \"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETWEEN-ASSESSMENT FORECASTING SETUP\n",
    "# ====================================\n",
    "# CRITICAL: This implements the correct \"between-assessment forecasting\" setup\n",
    "# \n",
    "# Key principle: Observed IPC defines targets; unobserved months are prediction times, not missing labels.\n",
    "#\n",
    "# Target: y_next = next observed IPC assessment (forward-lagged label)\n",
    "# Feature: IPC_last = last observed IPC before this row (forward-filled, constant between assessments)\n",
    "#\n",
    "# Rules:\n",
    "# - Only use IPC_last as IPC feature (no rolling, no multiple lags, no trends)\n",
    "# - CS_score is NOT the direct target (y_next is)\n",
    "# - Keep ALL rows (including last periods without future assessments)\n",
    "# - Filter to rows with valid y_next only when training models\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BETWEEN-ASSESSMENT FORECASTING SETUP\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nKey principle: Observed IPC defines targets; unobserved months are prediction times.\\n\")\n",
    "\n",
    "# Create region identifiers\n",
    "df['region'] = df['ADMIN0'] + '-' + df['ADMIN1']\n",
    "df['district'] = df['ADMIN0'] + '-' + df['ADMIN1'] + '-' + df['ADMIN2']\n",
    "\n",
    "# Sort by district (ADMIN2) and period to ensure deterministic operations\n",
    "df = df.sort_values(['ADMIN0', 'ADMIN1', 'ADMIN2', 'period']).reset_index(drop=True)\n",
    "\n",
    "# CS_score is already in the events dataset - just ensure numeric\n",
    "df['CS_score'] = pd.to_numeric(df['CS_score'], errors='coerce')\n",
    "\n",
    "# Create IPC_last: last observed IPC before this row (forward-filled)\n",
    "# This is the ONLY IPC feature allowed - it's stale and constant between assessments\n",
    "print(\"1. Creating IPC_last (last observed IPC, forward-filled)...\")\n",
    "df['IPC_last'] = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False)['CS_score'].transform(\n",
    "    lambda x: x.ffill()\n",
    ")\n",
    "\n",
    "# Create y_next: next observed IPC assessment (forward-lagged label)\n",
    "# This is the target variable - we predict the next assessment outcome\n",
    "print(\"2. Creating y_next (next observed IPC assessment - THE TARGET)...\")\n",
    "\n",
    "def get_next_assessment(group):\n",
    "    \"\"\"Get the next observed IPC assessment for each row\"\"\"\n",
    "    cs_values = group['CS_score'].values\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(cs_values)):\n",
    "        # Look forward to find next non-null value\n",
    "        found = False\n",
    "        for j in range(i + 1, len(cs_values)):\n",
    "            if pd.notna(cs_values[j]) and 1 <= cs_values[j] <= 5:\n",
    "                result.append(cs_values[j])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result.append(np.nan)\n",
    "    \n",
    "    return pd.Series(result, index=group.index)\n",
    "\n",
    "df['y_next'] = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False, group_keys=False).apply(\n",
    "    get_next_assessment\n",
    ")\n",
    "\n",
    "# Keep ALL rows - don't drop periods without future assessments\n",
    "# Rows without y_next (like 202402) can still be used for feature engineering\n",
    "# Filter to rows with valid y_next only when training models\n",
    "rows_with_y_next = df['y_next'].notna().sum()\n",
    "rows_without_y_next = df['y_next'].isna().sum()\n",
    "df = df[df['IPC_last'].isin([1, 2, 3, 4, 5])]\n",
    "print(f\"   Rows with y_next (can be used for training): {rows_with_y_next}\")\n",
    "print(f\"   Rows without y_next (last periods, feature engineering only): {rows_without_y_next}\")\n",
    "print(f\"   Total rows kept: {len(df)} (no periods dropped)\")\n",
    "\n",
    "# Clean y_next where it exists: ensure valid range (1-5) and convert to int\n",
    "# Only clean where y_next is not NaN\n",
    "mask_valid_y_next = df['y_next'].notna()\n",
    "df.loc[mask_valid_y_next, 'y_next'] = df.loc[mask_valid_y_next, 'y_next'].round()\n",
    "df.loc[mask_valid_y_next, 'y_next'] = df.loc[mask_valid_y_next, 'y_next'].clip(1, 5)\n",
    "df.loc[mask_valid_y_next, 'y_next'] = df.loc[mask_valid_y_next, 'y_next'].astype(int)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"IPC_last: last observed IPC (forward-filled, constant between assessments)\")\n",
    "print(f\"y_next: next observed IPC assessment (THE TARGET)\")\n",
    "print(f\"\\nIPC_last distribution:\")\n",
    "print(df['IPC_last'].value_counts().sort_index())\n",
    "print(f\"\\ny_next distribution (TARGET):\")\n",
    "print(df['y_next'].value_counts().sort_index())\n",
    "print(f\"\\nRows with valid y_next: {df['y_next'].notna().sum()}\")\n",
    "print(f\"Rows without y_next (last periods): {df['y_next'].isna().sum()}\")\n",
    "print(f\"Current DataFrame shape: {df.shape}\")\n",
    "print(f\"Period range: {df['period'].min()} to {df['period'].max()}\")\n",
    "\n",
    "# Show example for verification\n",
    "print(f\"\\n=== Example (first ADMIN2) ===\")\n",
    "if len(df) > 0:\n",
    "    example_admin2 = df['ADMIN2'].iloc[0]\n",
    "    example = df[df['ADMIN2'] == example_admin2].head(12)[['ADMIN2', 'period', 'CS_score', 'IPC_last', 'y_next']]\n",
    "    print(example.to_string(index=False))\n",
    "    print(f\"\\nNote: IPC_last is constant between assessments, y_next is the next assessment value\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article coverage by IPC score and ADMIN0\n",
    "# ==========================================\n",
    "\n",
    "df_ipc = df[df['IPC_last'].notna()].copy()\n",
    "df_ipc['has_articles'] = df_ipc['valid_SOURCEURL'].apply(\n",
    "    lambda x: x.size > 0 if isinstance(x, np.ndarray) else bool(x) if x is not None else False\n",
    ")\n",
    "\n",
    "total = len(df_ipc)\n",
    "print(f\"Total rows (with IPC_last): {total:,}\")\n",
    "print(f\"Rows with articles: {df_ipc['has_articles'].sum():,} ({df_ipc['has_articles'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Breakdown by IPC_last\n",
    "print(\"\\nBreakdown by IPC_last:\")\n",
    "breakdown = df_ipc.groupby('IPC_last').agg(\n",
    "    total=('has_articles', 'size'),\n",
    "    with_articles=('has_articles', 'sum'),\n",
    ")\n",
    "breakdown['pct_articles'] = (breakdown['with_articles'] / breakdown['total'] * 100).round(1)\n",
    "print(breakdown)\n",
    "\n",
    "# Breakdown by ADMIN0\n",
    "print(\"\\nBreakdown by ADMIN0:\")\n",
    "breakdown_admin0 = df_ipc.groupby('ADMIN0').agg(\n",
    "    total=('has_articles', 'size'),\n",
    "    with_articles=('has_articles', 'sum'),\n",
    "    admin2_total=('ADMIN2', 'nunique'),\n",
    ")\n",
    "admin2_cov = df_ipc[df_ipc['has_articles']].groupby('ADMIN0')['ADMIN2'].nunique().rename('admin2_with_coverage')\n",
    "breakdown_admin0 = breakdown_admin0.join(admin2_cov, how='left').fillna({'admin2_with_coverage': 0})\n",
    "breakdown_admin0['admin2_with_coverage'] = breakdown_admin0['admin2_with_coverage'].astype(int)\n",
    "breakdown_admin0['pct_admin2_covered'] = (breakdown_admin0['admin2_with_coverage'] / breakdown_admin0['admin2_total'] * 100).round(1)\n",
    "breakdown_admin0['pct_articles'] = (breakdown_admin0['with_articles'] / breakdown_admin0['total'] * 100).round(1)\n",
    "breakdown_admin0 = breakdown_admin0.sort_values('total', ascending=False)\n",
    "print(breakdown_admin0)\n",
    "\n",
    "# Admin1 propagation gain\n",
    "admin1_coverage = df_ipc.groupby(['ADMIN0', 'ADMIN1', 'period'])['has_articles'].transform('max').astype(bool)\n",
    "o, p = df_ipc['has_articles'].sum(), admin1_coverage.sum()\n",
    "print(f\"\\nAdmin1 propagation: {o:,} ({o/total*100:.1f}%) -> {p:,} ({p/total*100:.1f}%), gain +{p-o:,} ({(p-o)/total*100:.1f}%)\")\n",
    "\n",
    "# Breakdown by ADMIN0 after admin1 propagation\n",
    "print(\"\\nBreakdown by ADMIN0 (after admin1 propagation):\")\n",
    "df_ipc['has_articles_admin1'] = admin1_coverage.values\n",
    "breakdown_prop = df_ipc.groupby('ADMIN0').agg(\n",
    "    total=('has_articles', 'size'),\n",
    "    admin2_total=('ADMIN2', 'nunique'),\n",
    "    pct_admin2=('has_articles', 'mean'),\n",
    "    pct_admin1=('has_articles_admin1', 'mean'),\n",
    ")\n",
    "breakdown_prop['pct_admin2'] = (breakdown_prop['pct_admin2'] * 100).round(1)\n",
    "breakdown_prop['pct_admin1'] = (breakdown_prop['pct_admin1'] * 100).round(1)\n",
    "breakdown_prop['gain_pp'] = (breakdown_prop['pct_admin1'] - breakdown_prop['pct_admin2']).round(1)\n",
    "breakdown_prop = breakdown_prop.sort_values('total', ascending=False)\n",
    "print(breakdown_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(df['period']))\n",
    "print(max(df['period']))\n",
    "df = df.sort_values(['ADMIN0', 'ADMIN1', 'ADMIN2', 'period'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE FEATURE ENGINEERING\n",
    "# ===================================\n",
    "# This cell performs ALL feature engineering for IPC and GDELT Events features\n",
    "# At this point: lists are NOT aggregated yet, y_next and IPC_last exist\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPREHENSIVE FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nStarting with {len(df)} rows\")\n",
    "print(f\"Columns before feature engineering: {len(df.columns)}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. AGGREGATE GDELT LIST FEATURES\n",
    "# ============================================================================\n",
    "print(\"1. Aggregating GDELT list features...\")\n",
    "\n",
    "# Helper functions (already defined in previous cell, but ensure they exist)\n",
    "def safe_list_agg(lst, func):\n",
    "    \"\"\"Safely aggregate a list, handling None, empty lists, and non-numeric values\"\"\"\n",
    "    if lst is None:\n",
    "        return np.nan\n",
    "    if isinstance(lst, np.ndarray):\n",
    "        if lst.size == 0:\n",
    "            return np.nan\n",
    "        lst = lst.tolist()\n",
    "    try:\n",
    "        if pd.isna(lst):\n",
    "            return np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    if isinstance(lst, (int, float)):\n",
    "        return float(lst)\n",
    "    if isinstance(lst, str):\n",
    "        try:\n",
    "            if lst.startswith('[') or lst.startswith('('):\n",
    "                lst = eval(lst)\n",
    "            else:\n",
    "                return float(lst)\n",
    "        except:\n",
    "            return np.nan\n",
    "    if not isinstance(lst, (list, tuple)):\n",
    "        return np.nan\n",
    "    if len(lst) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        numeric_lst = []\n",
    "        for x in lst:\n",
    "            try:\n",
    "                if pd.isna(x) or x is None:\n",
    "                    continue\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "            try:\n",
    "                val = float(x)\n",
    "                if not np.isinf(val) and not np.isnan(val):\n",
    "                    numeric_lst.append(val)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "        if len(numeric_lst) == 0:\n",
    "            return np.nan\n",
    "        result = func(numeric_lst)\n",
    "        return float(result) if not np.isnan(result) and not np.isinf(result) else np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "def safe_list_count(x):\n",
    "    \"\"\"Safely count elements in a list/array\"\"\"\n",
    "    if x is None:\n",
    "        return 0\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.size if x.size > 0 else 0\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return len(x)\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return 0\n",
    "        return 1\n",
    "    except (ValueError, TypeError):\n",
    "        return 1\n",
    "\n",
    "def aggregate_list_features(df, list_cols, prefix=\"\"):\n",
    "    \"\"\"Aggregate list columns into meaningful statistical features for NLP-derived data\n",
    "    \n",
    "    For noisy NLP features, we keep only:\n",
    "    - mean: central tendency\n",
    "    - count: volume indicator\n",
    "    - sum: total (especially useful for frequencies/counts)\n",
    "    - max: peak intensity (only for crisis indicators)\n",
    "    \n",
    "    We skip: min (usually 0), std (variance not meaningful for noisy signals)\n",
    "    \"\"\"\n",
    "    new_cols = {}\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    for col in list_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        base_name = col.replace('_list', '')\n",
    "        if prefix:\n",
    "            base_name = f\"{prefix}_{base_name}\"\n",
    "        \n",
    "        # For text columns (NER, clean_text), only create count\n",
    "        if 'NER' in col or 'clean_text' in col:\n",
    "            new_cols[f\"{base_name}_count\"] = df[col].apply(safe_list_count)\n",
    "        else:\n",
    "            # For numeric columns, create meaningful aggregations only\n",
    "            # Mean: central tendency (most important for noisy signals)\n",
    "            new_cols[f\"{base_name}_mean\"] = df[col].apply(lambda x: safe_list_agg(x, np.mean))\n",
    "            \n",
    "            # Count: volume indicator (how many articles/events)\n",
    "            new_cols[f\"{base_name}_count\"] = df[col].apply(safe_list_count)\n",
    "            \n",
    "            # Sum: total (especially useful for frequencies and counts)\n",
    "            new_cols[f\"{base_name}_sum\"] = df[col].apply(lambda x: safe_list_agg(x, np.sum))\n",
    "            \n",
    "            # Max: peak intensity (only for crisis indicators where peaks matter)\n",
    "            # Check if this is a crisis-related feature\n",
    "            is_crisis_feature = any(x in col.lower() for x in ['fatalities', 'displaced', 'injured', \n",
    "                                                                 'violence', 'torture', 'crisis'])\n",
    "            if is_crisis_feature:\n",
    "                new_cols[f\"{base_name}_max\"] = df[col].apply(lambda x: safe_list_agg(x, np.max))\n",
    "            \n",
    "            # Skip: min (usually 0), std (variance not meaningful for noisy NLP signals)\n",
    "        \n",
    "        cols_to_drop.append(col)\n",
    "    \n",
    "    if new_cols:\n",
    "        new_df = pd.DataFrame(new_cols, index=df.index)\n",
    "        df = pd.concat([df, new_df], axis=1)\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Find and aggregate list columns (events only, no merge suffix)\n",
    "list_cols = [c for c in df.columns if '_list' in c]\n",
    "print(f\"   Found {len(list_cols)} list columns\")\n",
    "\n",
    "if list_cols:\n",
    "    print(\"   Aggregating events features...\")\n",
    "    df = aggregate_list_features(df, list_cols, prefix=\"evt\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CLEAN AND PREPARE IPC FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n2. Cleaning IPC features...\")\n",
    "\n",
    "# Clean IPC_last: round to nearest integer and ensure valid range\n",
    "df['IPC_last'] = df['IPC_last'].round()\n",
    "# Keep IPC_last as float for now (can filter invalid values later if needed)\n",
    "# Don't drop rows here - keep all periods\n",
    "\n",
    "print(f\"   IPC_last range: {df['IPC_last'].min():.1f} to {df['IPC_last'].max():.1f}\")\n",
    "print(f\"   Valid IPC_last (1-5): {(df['IPC_last'].between(1, 5, inclusive='both')).sum()} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CREATE TEMPORAL FEATURES FOR GDELT\n",
    "# ============================================================================\n",
    "print(\"\\n3. Creating temporal features for GDELT...\")\n",
    "\n",
    "# Focus on most reliable features for temporal patterns\n",
    "# Prioritize: sentiment, crisis indicators, food security\n",
    "key_gdelt_features = [\n",
    "    # Sentiment (most reliable NLP signals)\n",
    "    'evt_compound_score_mean', 'evt_sentiment.compound_mean',\n",
    "    \n",
    "    # Crisis indicators (high signal-to-noise)\n",
    "    'evt_fatalities_freq_mean', 'evt_displaced_freq_mean',\n",
    "    \n",
    "    # Food security (directly relevant to IPC)\n",
    "    'evt_food_insecurity_freq_mean',\n",
    "    \n",
    "    # Economic/agricultural (relevant but less reliable)\n",
    "    'evt_economic_shocks_freq_mean', 'evt_agriculture_freq_mean',\n",
    "]\n",
    "\n",
    "# Filter to features that actually exist\n",
    "key_gdelt_features = [f for f in key_gdelt_features if f in df.columns]\n",
    "\n",
    "print(f\"   Creating temporal features for {len(key_gdelt_features)} key GDELT features\")\n",
    "\n",
    "# Ensure sorted for lag operations\n",
    "df = df.sort_values(['ADMIN0', 'ADMIN1', 'ADMIN2', 'period']).reset_index(drop=True)\n",
    "\n",
    "# Create rolling windows (smoothing noise - most useful for NLP features)\n",
    "# Use 3 and 6 periods to capture short and medium-term trends\n",
    "for window in [3, 6]:\n",
    "    for feat in key_gdelt_features:\n",
    "        df[f\"{feat}_rolling_{window}\"] = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False)[feat].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "\n",
    "# Create lags (1 and 2 periods only - reduce noise)\n",
    "# Lags can capture trends but too many lags add noise\n",
    "for lag in [1, 2]:\n",
    "    for feat in key_gdelt_features:\n",
    "        df[f\"{feat}_lag{lag}\"] = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False)[feat].shift(lag)\n",
    "\n",
    "# Create escalation indicators (binary - less noisy than continuous change)\n",
    "# Use rolling mean comparison instead of raw change to reduce noise\n",
    "for feat in key_gdelt_features:\n",
    "    rolling_3 = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False)[feat].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "    )\n",
    "    rolling_6 = df.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'], sort=False)[feat].transform(\n",
    "        lambda x: x.rolling(window=6, min_periods=2).mean()\n",
    "    )\n",
    "    # Escalation: current 3-period average > 6-period average\n",
    "    df[f\"{feat}_escalation\"] = (rolling_3 > rolling_6).astype(int)\n",
    "\n",
    "# Skip: change, pct_change, anomaly (too noisy for NLP-derived features)\n",
    "\n",
    "print(f\"   Created temporal features: rolling windows (3, 6 periods), lags (1, 2 periods), escalation indicators\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. CREATE FEATURE INDICATORS AND INTERACTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n4. Creating feature indicators and interactions...\")\n",
    "\n",
    "# GDELT feature availability indicator\n",
    "gdelt_cols = [c for c in df.columns if c.startswith('evt_')]\n",
    "if gdelt_cols:\n",
    "    has_gdelt = df[gdelt_cols].notna().any(axis=1)\n",
    "    df['has_gdelt'] = has_gdelt.astype(int)\n",
    "else:\n",
    "    df['has_gdelt'] = 0\n",
    "\n",
    "# Sentiment features from events\n",
    "\n",
    "# Combine crisis indicators\n",
    "crisis_features = [c for c in df.columns if any(x in c for x in ['fatalities', 'displaced', 'injured']) \n",
    "                   and c.endswith('_mean') and c.startswith('evt_')]\n",
    "if crisis_features:\n",
    "    df['crisis_intensity'] = df[crisis_features].fillna(0).sum(axis=1)\n",
    "\n",
    "# Food security combined\n",
    "food_features = [c for c in df.columns if 'food_insecurity' in c and c.endswith('_mean') \n",
    "                 and c.startswith('evt_')]\n",
    "if food_features:\n",
    "    df['food_security_combined'] = df[food_features].fillna(0).mean(axis=1)\n",
    "\n",
    "print(f\"   Created interaction and combined features\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. CREATE GEOGRAPHIC DUMMY VARIABLES\n",
    "# ============================================================================\n",
    "print(\"\\n5. Creating geographic dummy variables...\")\n",
    "\n",
    "# Only create dummies for base geographic identifiers (ADMIN0, ADMIN1, ADMIN2)\n",
    "# Note: 'region' and 'district' are redundant (derived from ADMIN0+ADMIN1 and ADMIN0+ADMIN1+ADMIN2)\n",
    "geographic_cols = []\n",
    "for col in ['ADMIN0', 'ADMIN1', 'ADMIN2']:\n",
    "    if col in df.columns:\n",
    "        # Create dummy variables (one-hot encoding)\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        geographic_cols.extend(dummies.columns.tolist())\n",
    "        print(f\"   Created {len(dummies.columns)} dummy variables for {col}\")\n",
    "\n",
    "geographic_features = geographic_cols\n",
    "print(f\"   Total geographic features: {len(geographic_features)}\")\n",
    "print(f\"   Note: 'region' and 'district' are kept as categorical identifiers but not converted to dummies (redundant with ADMIN0+ADMIN1+ADMIN2)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(df)} rows\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "\n",
    "# Feature counts\n",
    "ipc_features = ['IPC_last']\n",
    "\n",
    "# GDELT base features: evt_ prefixed features\n",
    "gdelt_base = [c for c in df.columns if c.startswith('evt_') \n",
    "              and not any(x in c for x in ['_lag', '_rolling', '_escalation'])]\n",
    "\n",
    "# GDELT temporal features: evt_ prefixed features with temporal patterns\n",
    "gdelt_temporal = [c for c in df.columns if c.startswith('evt_') \n",
    "                   and any(x in c for x in ['_lag', '_rolling', '_escalation'])]\n",
    "\n",
    "# Geographic features were created as dummies in section 5 above\n",
    "# geographic_features is already set to geographic_cols\n",
    "\n",
    "# Geographic features: only ADMIN0, ADMIN1, ADMIN2 are converted to dummies\n",
    "# 'region' and 'district' are kept as categorical identifiers for grouping but not converted to dummies (redundant)\n",
    "# Exclude original categorical columns from feature lists (but keep them in dataframe for grouping purposes)\n",
    "geographic_categorical_cols = ['ADMIN0', 'ADMIN1', 'ADMIN2', 'region', 'district']\n",
    "\n",
    "# Exclude all non-feature columns (geographic categoricals, metadata, scores, indicators, target, list columns)\n",
    "excluded_cols = (ipc_features + gdelt_base + gdelt_temporal + geographic_features +\n",
    "                 ['y_next', 'has_gdelt', 'has_articles',\n",
    "                  'CS_score',\n",
    "                  'period', 'SQLDATE', 'EventCode', 'SOURCEURL', 'NumMentions', 'NumSources', \n",
    "                  'NumArticles', 'valid_SOURCEURL'] +\n",
    "                 geographic_categorical_cols +\n",
    "                 # Also exclude any remaining list columns that weren't aggregated\n",
    "                 [c for c in df.columns if '_list' in c])\n",
    "other_features = [c for c in df.columns if c not in excluded_cols]\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - IPC features: {len(ipc_features)}\")\n",
    "print(f\"  - GDELT base features: {len(gdelt_base)} (mean, count, sum, max for crisis)\")\n",
    "print(f\"  - GDELT temporal features: {len(gdelt_temporal)} (rolling windows, lags, escalation)\")\n",
    "print(f\"  - Geographic features: {len(geographic_features)} (dummy variables)\")\n",
    "print(f\"  - Other features: {len(other_features)}\")\n",
    "print(f\"  - Total features: {len(ipc_features) + len(gdelt_base) + len(gdelt_temporal) + len(geographic_features) + len(other_features)}\")\n",
    "print(f\"\\nNote: Simplified feature set for noisy NLP-derived signals:\")\n",
    "print(f\"  - Base: mean, count, sum (all features) + max (crisis features only)\")\n",
    "print(f\"  - Temporal: rolling windows (3, 6 periods), lags (1, 2 periods), escalation indicators\")\n",
    "print(f\"  - Removed: min, std, change, pct_change, anomaly (too noisy for NLP features)\")\n",
    "\n",
    "print(f\"\\nRows with y_next: {df['y_next'].notna().sum()} ({df['y_next'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"Rows with IPC_last: {df['IPC_last'].notna().sum()} ({df['IPC_last'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"Rows with GDELT features: {df['has_gdelt'].sum()} ({df['has_gdelt'].mean()*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DROP PROCESSED/METADATA COLUMNS\n",
    "# ============================================================================\n",
    "print(\"\\n6. Dropping processed metadata columns...\")\n",
    "\n",
    "cols_to_drop = ['SQLDATE', 'EventCode', 'SOURCEURL', 'NumMentions', \n",
    "                'NumSources', 'NumArticles', 'valid_SOURCEURL']\n",
    "# Only drop columns that exist\n",
    "cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
    "if cols_to_drop:\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    print(f\"   Dropped {len(cols_to_drop)} metadata columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"READY FOR MODELING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFeature sets available:\")\n",
    "print(f\"  - IPC only: {len(ipc_features)} IPC features + {len(geographic_features)} geographic features\")\n",
    "print(f\"  - IPC + GDELT base: {len(ipc_features)} IPC + {len(gdelt_base)} GDELT base + {len(geographic_features)} geographic\")\n",
    "print(f\"  - IPC + GDELT + temporal: {len(ipc_features)} IPC + {len(gdelt_base)} GDELT base + {len(gdelt_temporal)} GDELT temporal + {len(geographic_features)} geographic\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(df['period']))\n",
    "print(max(df['period']))\n",
    "df = df.sort_values(['ADMIN0', 'ADMIN1', 'ADMIN2', 'period'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure train and test, and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NAIVE BASELINE MODELS\n",
    "# ============================================================================\n",
    "# PPS     — Previous Period Score: predict y_next = IPC_last (no-change)\n",
    "# SPLY    — Same Period Last Year: CS_score from ~12 months ago\n",
    "# Max-2PP — Max of 2 Previous Periods: max CS_score of last 2 assessments\n",
    "#\n",
    "# Evaluated on every assessment period that has y_next data, then averaged.\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "admin_cols = ['ADMIN0', 'ADMIN1', 'ADMIN2']\n",
    "\n",
    "# All assessment periods with valid CS_score data\n",
    "eval_periods = sorted(\n",
    "    df.loc[df['CS_score'].between(1, 5), 'period'].unique()\n",
    ")\n",
    "\n",
    "print(f\"Evaluating baselines on {len(eval_periods)} assessment periods: {eval_periods[0]} → {eval_periods[-1]}\\n\")\n",
    "\n",
    "# ── Evaluate each baseline across all periods ────────────────────────────────\n",
    "baseline_names = ['PPS', 'SPLY', 'Max-2PP']\n",
    "period_results = {name: [] for name in baseline_names}\n",
    "\n",
    "for test_period in eval_periods:\n",
    "    test = df[(df['period'] == test_period) & df['CS_score'].between(1, 5)].copy()\n",
    "    train = df[(df['period'] < test_period) & df['CS_score'].between(1, 5)].copy()\n",
    "    train_periods = sorted(train['period'].unique())\n",
    "\n",
    "    if len(test) == 0 or len(train_periods) < 2:\n",
    "        continue\n",
    "\n",
    "    y_test = test['CS_score'].astype(int)\n",
    "\n",
    "    # PPS: previous assessment's CS_score (last training period, NOT current)\n",
    "    pps_lookup = (train[train['period'] == train_periods[-1]][admin_cols + ['CS_score']]\n",
    "                  .drop_duplicates(admin_cols))\n",
    "    pps_merged = test.merge(pps_lookup.rename(columns={'CS_score': 'pred'}),\n",
    "                            on=admin_cols, how='left')\n",
    "    pps_pred = pps_merged['pred'].fillna(0).astype(int)\n",
    "\n",
    "    # SPLY: CS_score from closest assessment ~12 months before test\n",
    "    target_sply = str(int(test_period) - 100)\n",
    "    sply_period = min(train_periods, key=lambda p: abs(int(p) - int(target_sply)))\n",
    "    sply_lookup = (train[train['period'] == sply_period][admin_cols + ['CS_score']]\n",
    "                   .drop_duplicates(admin_cols))\n",
    "    sply_merged = test.merge(sply_lookup.rename(columns={'CS_score': 'pred'}),\n",
    "                             on=admin_cols, how='left')\n",
    "    sply_pred = sply_merged['pred'].fillna(0).astype(int)\n",
    "\n",
    "    # Max-2PP: max CS_score from last 2 assessment periods\n",
    "    last2 = train_periods[-2:]\n",
    "    max2pp_lookup = (train[train['period'].isin(last2)]\n",
    "                     .groupby(admin_cols)['CS_score'].max().reset_index())\n",
    "    max2pp_merged = test.merge(max2pp_lookup.rename(columns={'CS_score': 'pred'}),\n",
    "                               on=admin_cols, how='left')\n",
    "    max2pp_pred = max2pp_merged['pred'].fillna(0).astype(int)\n",
    "\n",
    "    preds = {'PPS': pps_pred, 'SPLY': sply_pred, 'Max-2PP': max2pp_pred}\n",
    "\n",
    "    for name in baseline_names:\n",
    "        period_results[name].append({\n",
    "            'period': test_period,\n",
    "            'n_test': len(test),\n",
    "            'accuracy': accuracy_score(y_test, preds[name]),\n",
    "            'precision': precision_score(y_test, preds[name], average='weighted', zero_division=0),\n",
    "            'recall': recall_score(y_test, preds[name], average='weighted', zero_division=0),\n",
    "            'f1': f1_score(y_test, preds[name], average='weighted', zero_division=0),\n",
    "        })\n",
    "\n",
    "# ── Summary ──────────────────────────────────────────────────────────────────\n",
    "rows = []\n",
    "for name in baseline_names:\n",
    "    res = period_results[name]\n",
    "    rows.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': np.mean([r['accuracy'] for r in res]),\n",
    "        'Precision': np.mean([r['precision'] for r in res]),\n",
    "        'Recall': np.mean([r['recall'] for r in res]),\n",
    "        'F1': np.mean([r['f1'] for r in res]),\n",
    "        'N Periods': len(res),\n",
    "        'Total Test': sum(r['n_test'] for r in res),\n",
    "    })\n",
    "\n",
    "baseline_summary = pd.DataFrame(rows)\n",
    "print(baseline_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_periods = 20     # months of training data before each test assessment\n",
    "n_eval_periods = 3          # number of IPC assessment periods to evaluate (backwards from latest)\n",
    "min_obs_per_assessment = 50 # minimum admin2 areas scored to qualify as an assessment period\n",
    "\n",
    "# Optional: set to None to auto-detect latest assessment, or specify e.g. 202407\n",
    "start_period = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROLLING WINDOW EVALUATION — TEST ON IPC ASSESSMENT PERIODS\n",
    "# ============================================================================\n",
    "# Strategy:\n",
    "#   - Identify IPC assessment periods (months where FEWS NET published scores\n",
    "#     for >= min_obs_per_assessment admin2 areas).\n",
    "#   - Test on each assessment period: rows with valid y_next → predict next IPC.\n",
    "#   - Train on all prior periods (up to n_training_periods months before).\n",
    "#   - No leakage: IPC_last tells the model the *current* assessment;\n",
    "#     y_next is the *future* assessment — different values.\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "all_periods = sorted(df['period'].unique())\n",
    "\n",
    "# ── 1. Identify IPC assessment periods ──────────────────────────────────────\n",
    "ipc_obs_per_period = df[df['CS_score'].between(1, 5)].groupby('period').size()\n",
    "assessment_periods = sorted(ipc_obs_per_period.index.tolist())\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IPC ASSESSMENT PERIODS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal periods in data: {len(all_periods)}  ({all_periods[0]} → {all_periods[-1]})\")\n",
    "print(f\"Assessment periods (with CS_score data): {len(assessment_periods)}\\n\")\n",
    "for p in assessment_periods:\n",
    "    print(f\"  {p}:  {ipc_obs_per_period[p]:>5,} scored\")\n",
    "\n",
    "# ── 2. Select evaluation assessment periods (backwards from latest) ─────────\n",
    "if start_period is not None:\n",
    "    candidates = [p for p in assessment_periods if p <= start_period]\n",
    "else:\n",
    "    candidates = list(assessment_periods)\n",
    "\n",
    "eval_assessments = candidates[-n_eval_periods:]  # latest N\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ROLLING WINDOW EVALUATION SETUP\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  - Training window:       {n_training_periods} periods before test assessment\")\n",
    "print(f\"  - Assessments to test:   {len(eval_assessments)} (of {len(assessment_periods)} total)\")\n",
    "print(f\"  - Assessment periods:    {len(assessment_periods)}\")\n",
    "\n",
    "# ── 3. Create evaluation splits ─────────────────────────────────────────────\n",
    "evaluation_splits = []\n",
    "\n",
    "for i, test_period in enumerate(reversed(eval_assessments)):\n",
    "    test_idx = all_periods.index(test_period)\n",
    "    train_end_idx = test_idx - 1  # everything BEFORE test period\n",
    "    train_start_idx = max(0, train_end_idx - n_training_periods + 1)\n",
    "\n",
    "    if train_end_idx < 0:\n",
    "        print(f\"\\n  ⚠️  Assessment {test_period}: no training data available — skipping\")\n",
    "        continue\n",
    "\n",
    "    train_periods = all_periods[train_start_idx:train_end_idx + 1]\n",
    "\n",
    "    evaluation_splits.append({\n",
    "        'eval_id': i + 1,\n",
    "        'test_period': test_period,\n",
    "        'n_scored': int(ipc_obs_per_period.get(test_period, 0)),\n",
    "        'train_periods': train_periods,\n",
    "        'train_start': train_periods[0],\n",
    "        'train_end': train_periods[-1],\n",
    "        'n_train_periods': len(train_periods),\n",
    "    })\n",
    "\n",
    "print(f\"\\nEvaluation schedule (latest → earliest):\\n\")\n",
    "for s in evaluation_splits:\n",
    "    print(f\"  Eval {s['eval_id']}: test {s['test_period']}  \"\n",
    "          f\"({s['n_scored']:,} scored)  |  \"\n",
    "          f\"train {s['train_start']} → {s['train_end']}  \"\n",
    "          f\"({s['n_train_periods']} periods)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Created {len(evaluation_splits)} evaluation splits\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE FEATURE SETS\n",
    "# ============================================================================\n",
    "if 'ipc_features' in globals():\n",
    "    ipc_feat = [c for c in ipc_features if c in df.columns]\n",
    "else:\n",
    "    ipc_feat = ['IPC_last']\n",
    "\n",
    "_temporal_suffixes = ('_rolling_', '_lag', '_escalation')\n",
    "\n",
    "if 'gdelt_features' in globals():\n",
    "    gdelt_base_feat = [c for c in gdelt_features if c in df.columns]\n",
    "else:\n",
    "    gdelt_base_feat = [c for c in df.columns\n",
    "                       if c.startswith('evt_') and not any(s in c for s in _temporal_suffixes)]\n",
    "\n",
    "if 'temporal_features' in globals():\n",
    "    gdelt_temporal_feat = [c for c in temporal_features if c in df.columns]\n",
    "else:\n",
    "    gdelt_temporal_feat = [c for c in df.columns\n",
    "                           if c.startswith('evt_') and any(s in c for s in _temporal_suffixes)]\n",
    "\n",
    "if 'geographic_features' in globals():\n",
    "    geographic_feat = [c for c in geographic_features if c in df.columns]\n",
    "else:\n",
    "    geographic_feat = [c for c in df.columns if c.startswith('geo_')]\n",
    "\n",
    "feature_sets = {\n",
    "    'IPC only':               ipc_feat + geographic_feat,\n",
    "    'IPC + GDELT base':       ipc_feat + gdelt_base_feat + geographic_feat,\n",
    "    'IPC + GDELT + temporal': ipc_feat + gdelt_base_feat + gdelt_temporal_feat + geographic_feat,\n",
    "}\n",
    "\n",
    "print(\"\\nFeature sets available:\")\n",
    "for name, features in feature_sets.items():\n",
    "    n_ipc = len([c for c in features if c in ipc_feat])\n",
    "    n_gdelt_base = len([c for c in features if c in gdelt_base_feat])\n",
    "    n_gdelt_temp = len([c for c in features if c in gdelt_temporal_feat])\n",
    "    n_geo = len([c for c in features if c in geographic_feat])\n",
    "    print(f\"  - {name}: {n_ipc} IPC + {n_gdelt_base} GDELT base + {n_gdelt_temp} GDELT temporal + {n_geo} geographic = {len(features)} total\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE MODELS\n",
    "# ============================================================================\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs'),\n",
    "        'needs_scaling': True,\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(\n",
    "            n_estimators=300, max_depth=None, min_samples_split=5,\n",
    "            min_samples_leaf=2, class_weight='balanced', random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        'needs_scaling': False,\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostClassifier(\n",
    "            iterations=500, depth=6, learning_rate=0.1,\n",
    "            loss_function='MultiClass', auto_class_weights='Balanced',\n",
    "            random_seed=42, verbose=0\n",
    "        ),\n",
    "        'needs_scaling': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"\\nModels to evaluate: {', '.join(models.keys())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN AND EVALUATE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING AND EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_results = {}  # keyed by (model_name, feature_set_name)\n",
    "\n",
    "for model_name, model_cfg in models.items():\n",
    "    for feature_set_name, feature_cols in feature_sets.items():\n",
    "        result_key = (model_name, feature_set_name)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"MODEL: {model_name}  |  FEATURE SET: {feature_set_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using {len(feature_cols)} features\")\n",
    "\n",
    "        feature_results = []\n",
    "\n",
    "        for split in evaluation_splits:\n",
    "            print(f\"\\n  ── Eval {split['eval_id']}: Assessment period {split['test_period']} ──\")\n",
    "\n",
    "            # ── Training set: all prior periods with valid y_next ────────\n",
    "            #    (includes inter-assessment rows with GDELT features)\n",
    "            train_df = df[\n",
    "                (df['period'].isin(split['train_periods'])) &\n",
    "                (df['y_next'].notna())\n",
    "            ].copy()\n",
    "\n",
    "            # ── Test set: rows from assessment period with valid CS_score ─\n",
    "            test_df = df[\n",
    "                (df['period'] == split['test_period']) &\n",
    "                (df['CS_score'].between(1, 5))\n",
    "            ].copy()\n",
    "\n",
    "            print(f\"  Training samples:   {len(train_df):,}\")\n",
    "            print(f\"  Test samples:       {len(test_df):,}  (admin2 areas in {split['test_period']})\")\n",
    "\n",
    "            if len(train_df) == 0:\n",
    "                print(f\"  ⚠️  Skipping — no training data\")\n",
    "                continue\n",
    "            if len(test_df) == 0:\n",
    "                print(f\"  ⚠️  Skipping — no test data\")\n",
    "                continue\n",
    "\n",
    "            # ── Prepare features and target ──────────────────────────────\n",
    "            X_train = train_df[feature_cols].fillna(0)\n",
    "            y_train = train_df['y_next'].astype(int)\n",
    "\n",
    "            X_test = test_df[feature_cols].fillna(0)\n",
    "            y_test = test_df['CS_score'].astype(int)\n",
    "\n",
    "            # ── Fix IPC_last leakage: at assessment periods IPC_last == CS_score,\n",
    "            #    so replace it with the previous assessment's score ────────\n",
    "            if 'IPC_last' in feature_cols:\n",
    "                ipc_col_idx = feature_cols.index('IPC_last')\n",
    "                # Find previous assessment period in training window\n",
    "                train_assessments = sorted(\n",
    "                    p for p in assessment_periods if p in split['train_periods']\n",
    "                )\n",
    "                if train_assessments:\n",
    "                    prev_period = train_assessments[-1]\n",
    "                    prev_ipc = (\n",
    "                        df.loc[(df['period'] == prev_period) & df['CS_score'].between(1, 5),\n",
    "                               ['ADMIN0', 'ADMIN1', 'ADMIN2', 'CS_score']]\n",
    "                        .drop_duplicates(['ADMIN0', 'ADMIN1', 'ADMIN2'])\n",
    "                        .rename(columns={'CS_score': '_prev_ipc'})\n",
    "                    )\n",
    "                    test_with_prev = test_df.merge(prev_ipc, on=['ADMIN0', 'ADMIN1', 'ADMIN2'], how='left')\n",
    "                    if isinstance(X_test, np.ndarray):\n",
    "                        X_test[:, ipc_col_idx] = test_with_prev['_prev_ipc'].fillna(0).values\n",
    "                    else:\n",
    "                        X_test['IPC_last'] = test_with_prev['_prev_ipc'].fillna(0).values\n",
    "\n",
    "            # ── Scale (only for models that need it) ─────────────────────\n",
    "            if model_cfg['needs_scaling']:\n",
    "                scaler = StandardScaler()\n",
    "                X_train_fit = scaler.fit_transform(X_train)\n",
    "                X_test_fit = scaler.transform(X_test)\n",
    "            else:\n",
    "                X_train_fit = X_train\n",
    "                X_test_fit = X_test\n",
    "\n",
    "            # ── Train ────────────────────────────────────────────────────\n",
    "            print(f\"  Training {model_name}...\")\n",
    "            model = clone(model_cfg['model'])\n",
    "            model.fit(X_train_fit, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test_fit)\n",
    "\n",
    "            # ── Metrics ──────────────────────────────────────────────────\n",
    "            accuracy  = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            recall    = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1        = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            cm        = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            feature_results.append({\n",
    "                'eval_id': split['eval_id'],\n",
    "                'test_period': split['test_period'],\n",
    "                'n_train': len(train_df),\n",
    "                'n_test': len(test_df),\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'confusion_matrix': cm\n",
    "            })\n",
    "\n",
    "            print(f\"\\n  Results  (n_test={len(test_df):,}):\")\n",
    "            print(f\"    Accuracy:  {accuracy:.4f}\")\n",
    "            print(f\"    Precision: {precision:.4f}\")\n",
    "            print(f\"    Recall:    {recall:.4f}\")\n",
    "            print(f\"    F1 Score:  {f1:.4f}\")\n",
    "            print(f\"\\n  Confusion Matrix:\\n    {cm}\")\n",
    "\n",
    "        all_results[result_key] = feature_results\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "if any(len(v) > 0 for v in all_results.values()):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY: AVERAGE RESULTS BY MODEL & FEATURE SET\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    summary_data = []\n",
    "    for (model_name, feature_set_name), results in all_results.items():\n",
    "        if len(results) == 0:\n",
    "            continue\n",
    "\n",
    "        avg_acc  = np.mean([r['accuracy']  for r in results])\n",
    "        avg_prec = np.mean([r['precision'] for r in results])\n",
    "        avg_rec  = np.mean([r['recall']    for r in results])\n",
    "        avg_f1   = np.mean([r['f1']        for r in results])\n",
    "        total_test = sum(r['n_test'] for r in results)\n",
    "\n",
    "        print(f\"\\n{model_name} — {feature_set_name}:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  Average Metrics (across {len(results)} assessments, {total_test:,} total test samples):\")\n",
    "        print(f\"    Accuracy:  {avg_acc:.4f}\")\n",
    "        print(f\"    Precision: {avg_prec:.4f}\")\n",
    "        print(f\"    Recall:    {avg_rec:.4f}\")\n",
    "        print(f\"    F1 Score:  {avg_f1:.4f}\")\n",
    "\n",
    "        # Per-evaluation breakdown\n",
    "        print(f\"\\n  Per assessment:\")\n",
    "        for r in results:\n",
    "            print(f\"    {r['test_period']}:  n={r['n_test']:>5,}  acc={r['accuracy']:.3f}  f1={r['f1']:.3f}\")\n",
    "\n",
    "        n_features = len(feature_sets[feature_set_name])\n",
    "        n_ipc = len([c for c in feature_sets[feature_set_name] if c in ipc_feat])\n",
    "        n_gdelt_base = len([c for c in feature_sets[feature_set_name] if c in gdelt_base_feat])\n",
    "        n_gdelt_temp = len([c for c in feature_sets[feature_set_name] if c in gdelt_temporal_feat])\n",
    "        n_geo = len([c for c in feature_sets[feature_set_name] if c in geographic_feat])\n",
    "\n",
    "        summary_data.append({\n",
    "            'Model': model_name,\n",
    "            'Feature Set': feature_set_name,\n",
    "            'N Features': n_features,\n",
    "            'IPC': n_ipc,\n",
    "            'GDELT Base': n_gdelt_base,\n",
    "            'GDELT Temporal': n_gdelt_temp,\n",
    "            'Geographic': n_geo,\n",
    "            'Accuracy': avg_acc,\n",
    "            'Precision': avg_prec,\n",
    "            'Recall': avg_rec,\n",
    "            'F1 Score': avg_f1,\n",
    "            'Total Test': total_test,\n",
    "            'N Evals': len(results),\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('F1 Score', ascending=False)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️  No evaluations completed — check data availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Literature Shows Better Results: Key Differences\n",
    "\n",
    "## Potential Reasons for Better Performance in Literature:\n",
    "\n",
    "1. **Different Prediction Tasks**:\n",
    "   - **Transitions/Changes**: Predicting when CS_score will worsen (crisis onset) rather than exact level\n",
    "   - **Early Warning**: Predicting 2-4 periods ahead (forecasting) rather than next period (nowcasting)\n",
    "   - **Binary Classification**: Predicting crisis (CS≥3) vs non-crisis (CS<3) rather than 5-class classification\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - **Temporal Patterns**: Using lagged and rolling features (as we just added) rather than only current-period values\n",
    "   - **Anomaly Detection**: Focusing on deviations from historical patterns\n",
    "   - **Interaction Features**: Combining GDELT with other data sources (weather, prices, etc.)\n",
    "\n",
    "3. **Data Coverage**:\n",
    "   - **Spatial Aggregation**: Some studies aggregate to ADMIN0 or ADMIN1 level where coverage is better\n",
    "   - **Temporal Aggregation**: Using quarterly rather than monthly data\n",
    "   - **Filtering**: Focusing on regions/periods with good GDELT coverage\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - **Recall for Rare Events**: Focusing on detecting crises (high recall for CS≥3) rather than overall accuracy\n",
    "   - **Early Detection**: Measuring how early they detect transitions, not just accuracy\n",
    "\n",
    "5. **Baseline Comparison**:\n",
    "   - **Weaker Baselines**: Some studies don't include `previous_CS` in baseline, making improvement easier to show\n",
    "   - **Different Baselines**: Comparing against simpler models or using different evaluation windows\n",
    "\n",
    "## Our Current Approach:\n",
    "- ✅ Now includes temporal GDELT features (lags, rolling windows, anomalies, escalation)\n",
    "- ✅ Uses same framework as previous work (allowing fair comparison)\n",
    "- ⚠️ Still predicting exact CS_score level (highly autocorrelated)\n",
    "- ⚠️ Using monthly data with CS_score available every 4 months\n",
    "\n",
    "## Potential Improvements:\n",
    "1. **Predict Transitions**: Predict if CS_score will worsen (CS_t+1 > CS_t) rather than exact value\n",
    "2. **Forecasting Horizon**: Predict 2-4 periods ahead instead of next period\n",
    "3. **Crisis Detection**: Binary classification (crisis vs non-crisis) with focus on recall\n",
    "4. **Feature Selection**: Use only temporal GDELT features, filter out low-importance current-period features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary\n",
    "\n",
    "### Features Created:\n",
    "\n",
    "1. **List Aggregations** (from events):\n",
    "   - Mean, Max, Sum, Count for all list features\n",
    "   - Prefixed with `evt_`\n",
    "\n",
    "2. **Derived Features**:\n",
    "   - Crisis severity indicators\n",
    "   - Coverage intensity metrics\n",
    "\n",
    "3. **Temporal Features**:\n",
    "   - Lag features (CS_score_lag1, lag2, lag3)\n",
    "   - Moving averages (ma2, ma3)\n",
    "   - Change and percentage change features\n",
    "   - Cyclical period encoding (sin/cos)\n",
    "\n",
    "4. **Geographic Features**:\n",
    "   - Aggregated CS_score by ADMIN0 and ADMIN1 levels\n",
    "   - Standard deviations by geographic level\n",
    "   - Count of regions with same score\n",
    "\n",
    "5. **Interaction Features**:\n",
    "   - Ratios (casualty_rate, aid_per_casualty)\n",
    "   - Normalized features (tone_abs_normalized)\n",
    "   - Coverage metrics (mentions_per_source, articles_per_source)\n",
    "\n",
    "### Next Steps for ML:\n",
    "\n",
    "1. **Feature Selection**: Consider using:\n",
    "   - Correlation-based selection\n",
    "   - Mutual information\n",
    "   - Recursive feature elimination\n",
    "   - L1 regularization (Lasso)\n",
    "\n",
    "2. **Categorical Encoding**: If you have categorical features:\n",
    "   - One-hot encoding for low cardinality\n",
    "   - Target encoding for high cardinality\n",
    "   - Embedding for very high cardinality\n",
    "\n",
    "3. **Scaling**: Consider:\n",
    "   - StandardScaler or MinMaxScaler for numeric features\n",
    "   - Especially important for distance-based algorithms\n",
    "\n",
    "4. **Model Suggestions**:\n",
    "   - Random Forest (handles non-linear relationships well)\n",
    "   - Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "   - Neural Networks (if you have enough data)\n",
    "   - Consider class weights if classes are imbalanced\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
