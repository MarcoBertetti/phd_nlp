{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, multilabel_confusion_matrix\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "events = pd.read_parquet(\"../data/gdelt/events/6_final/events_dataset_v2.parquet\")\n",
    "gkg = pd.read_parquet(\"../data/gdelt/gkg/6_final/gkg_dataset_v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(events.index))\n",
    "print(events.columns)\n",
    "events.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting Configuration\n",
    "# ============================\n",
    "# Set the forecast horizon: predict CS_score N periods ahead\n",
    "# Options: 1 (nowcasting), 2, 3, or 4 (forecasting)\n",
    "# Literature shows GDELT features are more valuable for forecasting (2-4 periods ahead)\n",
    "# because baseline (previous_CS) becomes less powerful with longer horizons\n",
    "\n",
    "FORECAST_HORIZON = 3  # Predict 3 periods ahead (can be changed to 2 or 4)\n",
    "\n",
    "print(f\"=== Forecasting Configuration ===\")\n",
    "print(f\"Forecast Horizon: {FORECAST_HORIZON} period(s) ahead\")\n",
    "if FORECAST_HORIZON == 1:\n",
    "    print(\"Mode: NOWCASTING (predicting next period)\")\n",
    "else:\n",
    "    print(f\"Mode: FORECASTING (predicting {FORECAST_HORIZON} periods ahead)\")\n",
    "print(f\"\\nWhy forecasting helps GDELT features:\")\n",
    "print(f\"  - Baseline 'previous_CS' becomes less predictive ({FORECAST_HORIZON} periods old)\")\n",
    "print(f\"  - GDELT temporal patterns can capture early warning signals\")\n",
    "print(f\"  - More realistic for early warning systems\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(events, gkg, on=[\"ADMIN0\", \"ADMIN1\", \"ADMIN2\", \"period\"], how=\"outer\", suffixes=(\"_events\", \"_gkg\"))\n",
    "print(len(df.index))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"ADMIN0\", \"ADMIN1\", \"ADMIN2\", \"period\"]\n",
    "\n",
    "def check_duplicates(df, name):\n",
    "    dupes = (\n",
    "        df\n",
    "        .groupby(key_cols)\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "        .query(\"n > 1\")\n",
    "    )\n",
    "    print(f\"{name}: {len(dupes)} duplicated keys\")\n",
    "    return dupes\n",
    "\n",
    "dupes_events = check_duplicates(events, \"events\")\n",
    "dupes_gkg = check_duplicates(gkg, \"gkg\")\n",
    "dupes_merged = check_duplicates(df, \"merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Availability Analysis - RIGHT AFTER MERGE\n",
    "# ================================================\n",
    "# This must be done BEFORE any feature engineering or filtering\n",
    "# to accurately assess data coverage using original SQLDATE and DATE arrays\n",
    "\n",
    "print(\"=== Data Coverage Analysis (After Merge) ===\\n\")\n",
    "\n",
    "# Total rows after merge\n",
    "total_rows = len(df)\n",
    "print(f\"1. Total rows after merge: {total_rows:,}\")\n",
    "\n",
    "# Function to check if arrays are empty\n",
    "def is_empty_array(x):\n",
    "    \"\"\"Check if an array/list is empty\"\"\"\n",
    "    if x is None:\n",
    "        return True\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.size == 0\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return True\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return len(x) == 0\n",
    "    return False\n",
    "\n",
    "# Check for events data - SQLDATE being empty means no events\n",
    "if 'SQLDATE' in df.columns:\n",
    "    df['has_events_data'] = (~df['SQLDATE'].apply(is_empty_array)).astype(int)\n",
    "    events_count = df['has_events_data'].sum()\n",
    "    print(f\"2. Rows with events data (non-empty SQLDATE): {events_count:,} ({events_count/total_rows*100:.1f}%)\")\n",
    "else:\n",
    "    df['has_events_data'] = 0\n",
    "    print(\"2. SQLDATE column not found - cannot check events data\")\n",
    "\n",
    "# Check for GKG data - DATE being empty means no GKG data  \n",
    "if 'DATE' in df.columns:\n",
    "    df['has_gkg_data'] = (~df['DATE'].apply(is_empty_array)).astype(int)\n",
    "    gkg_count = df['has_gkg_data'].sum()\n",
    "    print(f\"3. Rows with GKG data (non-empty DATE): {gkg_count:,} ({gkg_count/total_rows*100:.1f}%)\")\n",
    "else:\n",
    "    df['has_gkg_data'] = 0\n",
    "    print(\"3. DATE column not found - cannot check GKG data\")\n",
    "\n",
    "# Overall feature availability\n",
    "df['has_any_features'] = (df['has_events_data'] | df['has_gkg_data']).astype(int)\n",
    "features_count = df['has_any_features'].sum()\n",
    "print(f\"4. Rows with ANY GDELT features: {features_count:,} ({features_count/total_rows*100:.1f}%)\")\n",
    "print(f\"   Rows WITHOUT GDELT features: {total_rows - features_count:,} ({(total_rows - features_count)/total_rows*100:.1f}%)\")\n",
    "\n",
    "# Check CS_score availability\n",
    "valid_cs_count = 0\n",
    "valid_cs_with_features_count = 0\n",
    "\n",
    "if 'CS_score_events' in df.columns and 'CS_score_gkg' in df.columns:\n",
    "    df['CS_score'] = df['CS_score_events'].fillna(df['CS_score_gkg'])\n",
    "    df['CS_score'] = pd.to_numeric(df['CS_score'], errors='coerce')\n",
    "    valid_cs = df[(df['CS_score'] >= 1) & (df['CS_score'] <= 5) & (df['CS_score'].notna())]\n",
    "    valid_cs_count = len(valid_cs)\n",
    "    print(f\"\\n5. Rows with valid CS_score (1-5): {valid_cs_count:,} ({valid_cs_count/total_rows*100:.1f}%)\")\n",
    "    \n",
    "    # Rows with valid CS_score AND features\n",
    "    valid_cs_with_features = valid_cs[valid_cs['has_any_features'] == 1]\n",
    "    valid_cs_with_features_count = len(valid_cs_with_features)\n",
    "    print(f\"6. Rows with valid CS_score AND GDELT features: {valid_cs_with_features_count:,}\")\n",
    "    print(f\"   - Coverage: {valid_cs_with_features_count/valid_cs_count*100:.1f}% of valid CS_score rows\")\n",
    "    print(f\"   - Coverage: {valid_cs_with_features_count/total_rows*100:.1f}% of total rows\")\n",
    "else:\n",
    "    print(\"\\n5. CS_score columns not found\")\n",
    "\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"Total rows: {total_rows:,}\")\n",
    "if valid_cs_count > 0:\n",
    "    print(f\"Valid CS_score rows: {valid_cs_count:,}\")\n",
    "    print(f\"Valid CS_score + Features: {valid_cs_with_features_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for CS_score Prediction\n",
    "# ============================================\n",
    "\n",
    "def safe_list_agg(lst, func):\n",
    "    \"\"\"Safely aggregate a list, handling None, empty lists, and non-numeric values\"\"\"\n",
    "    # Handle None first\n",
    "    if lst is None:\n",
    "        return np.nan\n",
    "    \n",
    "    # Handle numpy arrays and lists\n",
    "    if isinstance(lst, np.ndarray):\n",
    "        if lst.size == 0:\n",
    "            return np.nan\n",
    "        # Convert to list for processing\n",
    "        lst = lst.tolist()\n",
    "    \n",
    "    # Check for pandas NA/NaN (must check after None and array checks)\n",
    "    try:\n",
    "        if pd.isna(lst):\n",
    "            return np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        # pd.isna() failed, might be array-like, continue processing\n",
    "        pass\n",
    "    \n",
    "    # Handle scalar numeric values\n",
    "    if isinstance(lst, (int, float)):\n",
    "        return float(lst)\n",
    "    \n",
    "    # Handle strings\n",
    "    if isinstance(lst, str):\n",
    "        try:\n",
    "            # Try to evaluate if it's a string representation of a list\n",
    "            if lst.startswith('[') or lst.startswith('('):\n",
    "                lst = eval(lst)\n",
    "            else:\n",
    "                # Try to convert single value\n",
    "                return float(lst)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Check if it's a list-like structure\n",
    "    if not isinstance(lst, (list, tuple)):\n",
    "        return np.nan\n",
    "    \n",
    "    # Handle empty lists\n",
    "    if len(lst) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Process list elements\n",
    "    try:\n",
    "        # Convert to numeric, filtering out non-numeric values\n",
    "        numeric_lst = []\n",
    "        for x in lst:\n",
    "            # Check for NaN/None values\n",
    "            try:\n",
    "                if pd.isna(x) or x is None:\n",
    "                    continue\n",
    "            except (ValueError, TypeError):\n",
    "                # pd.isna() might fail for some types, try to convert anyway\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                val = float(x)\n",
    "                if not np.isinf(val) and not np.isnan(val):\n",
    "                    numeric_lst.append(val)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        if len(numeric_lst) == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        result = func(numeric_lst)\n",
    "        return float(result) if not np.isnan(result) and not np.isinf(result) else np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "def safe_list_count(x):\n",
    "    \"\"\"Safely count elements in a list/array, handling various data types\"\"\"\n",
    "    if x is None:\n",
    "        return 0\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.size if x.size > 0 else 0\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return len(x)\n",
    "    # For scalar values, check if it's not NaN\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return 0\n",
    "        return 1\n",
    "    except (ValueError, TypeError):\n",
    "        # If pd.isna fails, assume it's a valid value\n",
    "        return 1\n",
    "\n",
    "def aggregate_list_features(df, list_cols, prefix=\"\"):\n",
    "    \"\"\"Aggregate list columns into multiple statistical features\"\"\"\n",
    "    # Collect all new columns in a dictionary to avoid fragmentation\n",
    "    new_cols = {}\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    for col in list_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        base_name = col.replace('_list', '').replace('_events', '').replace('_gkg', '')\n",
    "        if prefix:\n",
    "            base_name = f\"{prefix}_{base_name}\"\n",
    "        \n",
    "        # Compute all aggregations for this column\n",
    "        new_cols[f\"{base_name}_mean\"] = df[col].apply(lambda x: safe_list_agg(x, np.mean))\n",
    "        new_cols[f\"{base_name}_max\"] = df[col].apply(lambda x: safe_list_agg(x, np.max))\n",
    "        new_cols[f\"{base_name}_sum\"] = df[col].apply(lambda x: safe_list_agg(x, np.sum))\n",
    "        new_cols[f\"{base_name}_count\"] = df[col].apply(safe_list_count)\n",
    "        new_cols[f\"{base_name}_std\"] = df[col].apply(lambda x: safe_list_agg(x, np.std))\n",
    "        new_cols[f\"{base_name}_min\"] = df[col].apply(lambda x: safe_list_agg(x, np.min))\n",
    "        \n",
    "        # Track columns to drop\n",
    "        cols_to_drop.append(col)\n",
    "    \n",
    "    # Add all new columns at once using pd.concat to avoid fragmentation\n",
    "    if new_cols:\n",
    "        new_df = pd.DataFrame(new_cols, index=df.index)\n",
    "        df = pd.concat([df, new_df], axis=1)\n",
    "    \n",
    "    # Drop original list columns\n",
    "    if cols_to_drop:\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Step 1: Determine target variable\n",
    "# ===================================\n",
    "# IMPORTANT: CS_score from FEWSNET is only available roughly every 4 months.\n",
    "# Intermediary months can be used for feature engineering (lags, moving averages)\n",
    "# but will be filtered out before model training (only CS_score between 1-5 are valid).\n",
    "\n",
    "# Option 1: Use events CS_score as primary, fill with gkg if missing\n",
    "df['CS_score'] = df['CS_score_events'].fillna(df['CS_score_gkg'])\n",
    "\n",
    "# Option 2: Average if both exist (uncomment if preferred)\n",
    "# df['CS_score'] = df[['CS_score_events', 'CS_score_gkg']].mean(axis=1)\n",
    "\n",
    "# Option 3: Use maximum (uncomment if preferred)\n",
    "# df['CS_score'] = df[['CS_score_events', 'CS_score_gkg']].max(axis=1)\n",
    "\n",
    "print(f\"CS_score distribution (before filtering):\")\n",
    "print(df['CS_score'].value_counts().sort_index())\n",
    "print(f\"\\nMissing CS_score: {df['CS_score'].isna().sum()}\")\n",
    "print(f\"\\nNote: Intermediary months (with missing CS_score) will be used for\")\n",
    "print(f\"feature engineering but filtered out before model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Text Features: Remove nonsensical statistical aggregations\n",
    "# ===============================================================\n",
    "# NER and clean_text columns contain strings, so mean/std/min/max/sum don't make sense\n",
    "# Only count features are meaningful for text columns\n",
    "\n",
    "print(\"=== Fixing Text Features (NER and clean_text) ===\")\n",
    "\n",
    "# Identify text columns that have nonsensical statistical features\n",
    "text_stat_cols = [c for c in df.columns if (('NER' in c) or ('clean_text' in c)) and any(x in c for x in ['_mean', '_std', '_min', '_max', '_sum'])]\n",
    "\n",
    "print(f\"Found {len(text_stat_cols)} nonsensical text statistical features to remove:\")\n",
    "for col in sorted(text_stat_cols)[:20]:\n",
    "    print(f\"  - {col}\")\n",
    "if len(text_stat_cols) > 20:\n",
    "    print(f\"  ... and {len(text_stat_cols) - 20} more\")\n",
    "\n",
    "# Drop these columns\n",
    "if text_stat_cols:\n",
    "    df = df.drop(columns=text_stat_cols)\n",
    "\n",
    "# Keep only text count features (which are meaningful)\n",
    "text_count_cols = [c for c in df.columns if (('NER' in c) or ('clean_text' in c)) and '_count' in c]\n",
    "print(f\"\\nKept {len(text_count_cols)} meaningful text count features\")\n",
    "print(f\"DataFrame shape after fixing text features: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Final GDELT Features\n",
    "# ============================\n",
    "# Show all GDELT features after aggregation and cleanup to verify they make sense\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL GDELT FEATURES LIST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all GDELT features\n",
    "gdelt_features = [c for c in df.columns if c.startswith('evt_') or c.startswith('gkg_')]\n",
    "gdelt_features = sorted(gdelt_features)\n",
    "\n",
    "print(f\"\\nTotal GDELT features: {len(gdelt_features)}\\n\")\n",
    "\n",
    "# Group by feature type\n",
    "evt_features = [f for f in gdelt_features if f.startswith('evt_')]\n",
    "gkg_features = [f for f in gdelt_features if f.startswith('gkg_')]\n",
    "\n",
    "print(f\"Events (evt_) features: {len(evt_features)}\")\n",
    "print(f\"GKG (gkg_) features: {len(gkg_features)}\\n\")\n",
    "\n",
    "# Categorize features\n",
    "categories = {\n",
    "    'Sentiment': ['compound', 'sentiment', 'neg', 'neu', 'pos'],\n",
    "    'NER (Entity Recognition)': ['NER'],\n",
    "    'Text': ['clean_text'],\n",
    "    'Fatalities': ['fatalities'],\n",
    "    'Displaced': ['displaced'],\n",
    "    'Detained': ['detained'],\n",
    "    'Injured': ['injured'],\n",
    "    'Violence': ['sexual_violence', 'torture'],\n",
    "    'Economic': ['economic_shocks'],\n",
    "    'Agriculture': ['agriculture'],\n",
    "    'Weather': ['weather'],\n",
    "    'Food Security': ['food_insecurity'],\n",
    "    'Predictions': ['pred_impact', 'pred_urgency', 'pred_resource'],\n",
    "    'Temporal (Lags/Rolling)': ['_lag', '_rolling', '_anomaly', '_escalation', '_change']\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURES BY CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for category, keywords in categories.items():\n",
    "    matching = [f for f in gdelt_features if any(kw in f for kw in keywords)]\n",
    "    if matching:\n",
    "        print(f\"\\n{category} ({len(matching)} features):\")\n",
    "        for feat in sorted(matching)[:10]:\n",
    "            print(f\"  - {feat}\")\n",
    "        if len(matching) > 10:\n",
    "            print(f\"  ... and {len(matching) - 10} more\")\n",
    "\n",
    "# Show uncategorized features\n",
    "categorized = set()\n",
    "for keywords in categories.values():\n",
    "    for kw in keywords:\n",
    "        categorized.update([f for f in gdelt_features if kw in f])\n",
    "\n",
    "uncategorized = [f for f in gdelt_features if f not in categorized]\n",
    "if uncategorized:\n",
    "    print(f\"\\nUncategorized ({len(uncategorized)} features):\")\n",
    "    for feat in sorted(uncategorized)[:20]:\n",
    "        print(f\"  - {feat}\")\n",
    "    if len(uncategorized) > 20:\n",
    "        print(f\"  ... and {len(uncategorized) - 20} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE FEATURE LIST (Alphabetical)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEvents Features:\")\n",
    "for i, feat in enumerate(evt_features, 1):\n",
    "    print(f\"{i:3d}. {feat}\")\n",
    "\n",
    "print(f\"\\n\\nGKG Features:\")\n",
    "for i, feat in enumerate(gkg_features, 1):\n",
    "    print(f\"{i:3d}. {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"TOTAL: {len(gdelt_features)} GDELT features\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Aggregate list features from both datasets\n",
    "# ===================================================\n",
    "\n",
    "# Capture column count BEFORE aggregation\n",
    "cols_before_agg = len(df.columns)\n",
    "\n",
    "# Identify all list columns\n",
    "list_cols_events = [c for c in df.columns if '_list_events' in c]\n",
    "list_cols_gkg = [c for c in df.columns if '_list_gkg' in c]\n",
    "\n",
    "print(f\"Found {len(list_cols_events)} list columns from events\")\n",
    "print(f\"Found {len(list_cols_gkg)} list columns from gkg\")\n",
    "print(f\"Total list columns: {len(list_cols_events) + len(list_cols_gkg)}\")\n",
    "print(f\"Columns before aggregation: {cols_before_agg}\")\n",
    "\n",
    "# Aggregate events list features\n",
    "print(\"\\nAggregating events list features...\")\n",
    "df = aggregate_list_features(df, list_cols_events, prefix=\"evt\")\n",
    "\n",
    "# Aggregate gkg list features\n",
    "print(\"Aggregating gkg list features...\")\n",
    "df = aggregate_list_features(df, list_cols_gkg, prefix=\"gkg\")\n",
    "\n",
    "cols_after_agg = len(df.columns)\n",
    "print(f\"\\nDataFrame shape after aggregation: {df.shape}\")\n",
    "print(f\"Columns after aggregation: {cols_after_agg}\")\n",
    "\n",
    "# Feature Breakdown Analysis\n",
    "# ==========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE TRANSFORMATION BREAKDOWN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_list_cols = len(list_cols_events) + len(list_cols_gkg)\n",
    "features_per_list_col = 6  # mean, max, sum, count, std, min\n",
    "new_features_from_lists = total_list_cols * features_per_list_col\n",
    "non_list_cols_before = cols_before_agg - total_list_cols\n",
    "\n",
    "print(f\"\\n1. Starting point:\")\n",
    "print(f\"   - Total columns before aggregation: {cols_before_agg}\")\n",
    "print(f\"   - List columns to aggregate: {total_list_cols} (39 events + 39 gkg)\")\n",
    "print(f\"   - Non-list columns: {non_list_cols_before}\")\n",
    "\n",
    "print(f\"\\n2. Transformation:\")\n",
    "print(f\"   - Each list column → {features_per_list_col} features:\")\n",
    "print(f\"     * mean: average value in the list\")\n",
    "print(f\"     * max: maximum value in the list\")\n",
    "print(f\"     * sum: sum of all values in the list\")\n",
    "print(f\"     * count: number of elements in the list\")\n",
    "print(f\"     * std: standard deviation of values in the list\")\n",
    "print(f\"     * min: minimum value in the list\")\n",
    "print(f\"   - Total new features created: {total_list_cols} × {features_per_list_col} = {new_features_from_lists}\")\n",
    "\n",
    "print(f\"\\n3. Result:\")\n",
    "print(f\"   - Original non-list columns: {non_list_cols_before}\")\n",
    "print(f\"   - New aggregated features: {new_features_from_lists}\")\n",
    "print(f\"   - List columns removed: {total_list_cols}\")\n",
    "print(f\"   - Expected total: {non_list_cols_before} + {new_features_from_lists} = {non_list_cols_before + new_features_from_lists}\")\n",
    "print(f\"   - Actual total: {cols_after_agg}\")\n",
    "\n",
    "# Show sample of created features\n",
    "evt_features = [c for c in df.columns if c.startswith('evt_')]\n",
    "gkg_features = [c for c in df.columns if c.startswith('gkg_')]\n",
    "non_list_cols = [c for c in df.columns if not c.startswith('evt_') and not c.startswith('gkg_')]\n",
    "\n",
    "print(f\"\\n4. Column breakdown:\")\n",
    "print(f\"   - evt_* features: {len(evt_features)} (from events list columns)\")\n",
    "print(f\"   - gkg_* features: {len(gkg_features)} (from gkg list columns)\")\n",
    "print(f\"   - Other columns: {len(non_list_cols)} (identifiers, metadata, etc.)\")\n",
    "\n",
    "print(f\"\\n5. Sample features created:\")\n",
    "print(f\"\\n   Events features (first 15):\")\n",
    "for feat in sorted(evt_features)[:15]:\n",
    "    print(f\"      - {feat}\")\n",
    "if len(evt_features) > 15:\n",
    "    print(f\"      ... and {len(evt_features) - 15} more evt_ features\")\n",
    "\n",
    "print(f\"\\n   GKG features (first 15):\")\n",
    "for feat in sorted(gkg_features)[:15]:\n",
    "    print(f\"      - {feat}\")\n",
    "if len(gkg_features) > 15:\n",
    "    print(f\"      ... and {len(gkg_features) - 15} more gkg_ features\")\n",
    "\n",
    "print(f\"\\n6. Non-aggregated columns ({len(non_list_cols)}):\")\n",
    "for col in sorted(non_list_cols):\n",
    "    print(f\"      - {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create combined and interaction features\n",
    "# ================================================\n",
    "\n",
    "# Combine CS_score from both sources (if both exist, use average)\n",
    "df['CS_score_combined'] = df[['CS_score_events', 'CS_score_gkg']].mean(axis=1, skipna=True)\n",
    "df['CS_score_diff'] = df['CS_score_events'] - df['CS_score_gkg']\n",
    "df['has_both_scores'] = (df['CS_score_events'].notna() & df['CS_score_gkg'].notna()).astype(int)\n",
    "\n",
    "# Combine numeric features from GKG (these are already aggregated)\n",
    "# Create ratios and normalized features\n",
    "if 'n_killed' in df.columns:\n",
    "    df['casualty_rate'] = df['n_killed'] / (df['n_killed'] + df['n_injured'] + 1)  # +1 to avoid division by zero\n",
    "    df['total_casualties'] = df['n_killed'] + df['n_injured'] + df['n_missing']\n",
    "    df['aid_per_casualty'] = df['usd_aid'] / (df['total_casualties'] + 1)\n",
    "\n",
    "# Combine event counts from GKG themes\n",
    "theme_cols = [c for c in df.columns if '_related' in c]\n",
    "if theme_cols:\n",
    "    df['total_themes'] = df[theme_cols].sum(axis=1)\n",
    "    df['conflict_intensity'] = df['n_conflict_related'] / (df['total_themes'] + 1)\n",
    "    df['crisis_severity'] = (df['n_food_related'] + df['n_water_related'] + df['n_disease_related']) / (df['total_themes'] + 1)\n",
    "\n",
    "# Combine sentiment features (if aggregated from lists)\n",
    "sentiment_cols = [c for c in df.columns if 'sentiment' in c.lower() or 'compound' in c.lower() or 'neg' in c.lower() or 'pos' in c.lower()]\n",
    "if sentiment_cols:\n",
    "    # Create overall sentiment indicators\n",
    "    if 'evt_compound_mean' in df.columns and 'gkg_compound_mean' in df.columns:\n",
    "        df['sentiment_combined'] = (df['evt_compound_mean'].fillna(0) + df['gkg_compound_mean'].fillna(0)) / 2\n",
    "        df['sentiment_agreement'] = (df['evt_compound_mean'] * df['gkg_compound_mean'] > 0).astype(int)\n",
    "\n",
    "# Event coverage features\n",
    "if 'NumMentions' in df.columns:\n",
    "    df['mentions_per_source'] = df['NumMentions'] / (df['NumSources'] + 1)\n",
    "    df['articles_per_source'] = df['NumArticles'] / (df['NumSources'] + 1)\n",
    "    df['coverage_intensity'] = df['NumMentions'] * df['NumSources']\n",
    "\n",
    "# Tone features from GKG\n",
    "if 'tone' in df.columns:\n",
    "    df['tone_abs_normalized'] = df['tone_abs'] / (abs(df['tone']) + 1)\n",
    "    df['negative_tone'] = (df['tone'] < 0).astype(int)\n",
    "\n",
    "print(\"Created interaction and combined features\")\n",
    "print(f\"Current DataFrame shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create simple temporal features for FORECASTING\n",
    "# =======================================================\n",
    "# NOTE: Modified for forecasting (predicting N periods ahead)\n",
    "# We create simple, safe temporal features BEFORE split to prevent leakage.\n",
    "\n",
    "# Create region identifiers (matching previous work)\n",
    "df['region'] = df['ADMIN0'] + '-' + df['ADMIN1']\n",
    "df['district'] = df['ADMIN0'] + '-' + df['ADMIN1'] + '-' + df['ADMIN2']\n",
    "\n",
    "# Sort by region and period to ensure deterministic lags\n",
    "df = df.sort_values(['region', 'period']).reset_index(drop=True)\n",
    "\n",
    "# FORECASTING: Create target variable by shifting CS_score backward by FORECAST_HORIZON\n",
    "# At time t, we want to predict CS_score at time t+FORECAST_HORIZON\n",
    "# So we shift CS_score backward: CS_score_target[t] = CS_score[t+FORECAST_HORIZON]\n",
    "df['CS_score_target'] = df.groupby('region', sort=False)['CS_score'].shift(-FORECAST_HORIZON)\n",
    "\n",
    "# Simple temporal features for forecasting:\n",
    "# 1. previous_CS: CS_score from FORECAST_HORIZON periods ago (most recent available)\n",
    "#    For forecasting, this is less predictive than for nowcasting\n",
    "df['previous_CS'] = df.groupby('region', sort=False)['CS_score'].shift(FORECAST_HORIZON)\n",
    "\n",
    "# 2. transitions_prev: cumulative count of CS_score transitions up to t-FORECAST_HORIZON\n",
    "# Count changes, then cumsum and shift so it reflects info only up to t-FORECAST_HORIZON\n",
    "change_flag = (\n",
    "    df.groupby('region', sort=False)['CS_score']\n",
    "      .transform(lambda x: (x != x.shift()).astype(int))\n",
    ")\n",
    "df['transitions_prev'] = (\n",
    "    change_flag.groupby(df['region']).cumsum().shift(FORECAST_HORIZON).fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Also create CS_score at different lags for additional baseline features\n",
    "for lag in [1, 2, FORECAST_HORIZON]:\n",
    "    if lag != FORECAST_HORIZON:  # Don't duplicate previous_CS\n",
    "        df[f'CS_score_lag{lag}'] = df.groupby('region', sort=False)['CS_score'].shift(lag)\n",
    "\n",
    "print(f\"Created temporal features for {FORECAST_HORIZON}-period forecasting:\")\n",
    "print(f\"  - CS_score_target: target variable (CS_score shifted {FORECAST_HORIZON} periods forward)\")\n",
    "print(f\"  - previous_CS: CS_score from {FORECAST_HORIZON} periods ago\")\n",
    "print(f\"  - transitions_prev: transitions up to {FORECAST_HORIZON} periods ago\")\n",
    "print(f\"  - CS_score_lag1, CS_score_lag2: additional lag features\")\n",
    "print(f\"\\nCurrent DataFrame shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Filter to valid CS_score_target and prepare for FORECASTING models\n",
    "# ============================================================================\n",
    "# CRITICAL: For FORECASTING, we filter on CS_score_target (the future value we're predicting)\n",
    "# Filter to only rows where CS_score_target is between 1 and 5 (inclusive).\n",
    "# Following previous work framework: keep only last 7+FORECAST_HORIZON periods for evaluation.\n",
    "\n",
    "print(f\"=== Step 5: Filtering to Valid CS_score_target (Forecasting {FORECAST_HORIZON} periods ahead) ===\")\n",
    "\n",
    "# Ensure both CS_score (features) and CS_score_target (target) are numeric\n",
    "df['CS_score'] = pd.to_numeric(df['CS_score'], errors='coerce')\n",
    "df['CS_score_target'] = pd.to_numeric(df['CS_score_target'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values in CS_score_target (we need valid targets)\n",
    "initial_len = len(df)\n",
    "df = df[df['CS_score_target'].notna() & np.isfinite(df['CS_score_target'])].copy()\n",
    "if initial_len != len(df):\n",
    "    print(f\"Dropped {initial_len - len(df)} rows with invalid/missing CS_score_target\")\n",
    "\n",
    "# Round to nearest integer and convert to int\n",
    "if df['CS_score_target'].dtype == 'float64':\n",
    "    df['CS_score_target'] = df['CS_score_target'].round().astype(int)\n",
    "else:\n",
    "    df['CS_score_target'] = df['CS_score_target'].astype(int)\n",
    "\n",
    "# Ensure target is in valid range (1-5)\n",
    "df = df[df['CS_score_target'].between(1, 5, inclusive='both')].copy()\n",
    "\n",
    "# Keep only last 7+FORECAST_HORIZON periods for evaluation\n",
    "# We need extra periods because we're predicting forward\n",
    "all_periods = sorted(df['period'].unique())\n",
    "keep_periods = all_periods[-(7 + FORECAST_HORIZON):]\n",
    "df = df[df['period'].isin(keep_periods)].copy()\n",
    "\n",
    "print(f\"Final dataset: {len(df)} rows with valid CS_score_target (1-5)\")\n",
    "print(f\"Periods: {sorted(df['period'].unique())}\")\n",
    "print(f\"Note: Predicting CS_score {FORECAST_HORIZON} periods ahead\\n\")\n",
    "\n",
    "# Step 6: Split into train/test for FORECASTING\n",
    "# ==============================================\n",
    "# Split after feature creation (features already created in Step 4)\n",
    "# For forecasting: need to ensure test period has valid targets FORECAST_HORIZON periods ahead\n",
    "# Use last 5 periods for training, last period for testing\n",
    "\n",
    "test_period = df['period'].max()\n",
    "train = df[df['period'] < test_period].copy()\n",
    "train = train[train['period'].isin(sorted(train['period'].unique())[-5:])].copy()\n",
    "\n",
    "test = df[df['period'] == test_period].copy()\n",
    "\n",
    "print(f\"=== Step 6: Train/Test Split (Forecasting {FORECAST_HORIZON} periods ahead) ===\")\n",
    "print(f\"Test period: {test_period}\")\n",
    "print(f\"Train periods: {sorted(train['period'].unique())}\")\n",
    "print(f\"Train set: {len(train)} rows\")\n",
    "print(f\"Test set: {len(test)} rows\")\n",
    "print(f\"\\nNote: At time t, predicting CS_score at time t+{FORECAST_HORIZON}\\n\")\n",
    "\n",
    "# Drop rows where previous_CS is missing (matching previous work)\n",
    "train = train[train['previous_CS'].isin([1, 2, 3, 4, 5])].copy()\n",
    "test = test[test['previous_CS'].isin([1, 2, 3, 4, 5])].copy()\n",
    "\n",
    "print(f\"After dropping missing previous_CS:\")\n",
    "print(f\"Train set: {len(train)} rows\")\n",
    "print(f\"Test set: {len(test)} rows\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: Create Temporal Features from GDELT Data\n",
    "# ===================================================\n",
    "# CRITICAL: Create temporal patterns from GDELT features (lags, rolling windows, anomalies)\n",
    "# This matches how conflict features were engineered in previous work.\n",
    "# Literature shows that temporal patterns in news/social data are predictive, not just current values.\n",
    "\n",
    "print(\"=== Step 4b: Creating Temporal GDELT Features ===\\n\")\n",
    "\n",
    "# Identify key GDELT features to create temporal patterns from\n",
    "# Focus on features that might have predictive signal\n",
    "key_gdelt_features = [\n",
    "    # Sentiment features\n",
    "    'evt_compound_score_mean', 'evt_sentiment.compound_mean',\n",
    "    'gkg_compound_mean',\n",
    "    \n",
    "    # Food security indicators\n",
    "    'evt_food_insecurity_freq_mean', 'gkg_food_insecurity_freq_mean',\n",
    "    \n",
    "    # Crisis indicators\n",
    "    'evt_displaced_freq_mean', 'evt_fatalities_freq_mean',\n",
    "    'gkg_displaced_freq_mean', 'gkg_fatalities_freq_mean',\n",
    "    \n",
    "    # Economic/agricultural indicators\n",
    "    'evt_agriculture_freq_mean', 'evt_economic_shocks_freq_mean',\n",
    "    'gkg_agriculture_freq_mean',\n",
    "    \n",
    "    # Weather indicators\n",
    "    'evt_weather_freq_mean', 'gkg_weather_freq_mean'\n",
    "]\n",
    "\n",
    "# Keep only features that exist in the dataset\n",
    "key_gdelt_features = [f for f in key_gdelt_features if f in df.columns]\n",
    "print(f\"Found {len(key_gdelt_features)} key GDELT features for temporal engineering\")\n",
    "\n",
    "if len(key_gdelt_features) > 0:\n",
    "    # Ensure df is sorted by region and period\n",
    "    df = df.sort_values(['region', 'period']).reset_index(drop=True)\n",
    "    \n",
    "    # Create lagged features (1-3 periods back) - these capture historical patterns\n",
    "    print(\"Creating lagged features (lag1, lag2, lag3)...\")\n",
    "    for feat in key_gdelt_features:\n",
    "        for lag in [1, 2, 3]:\n",
    "            df[f'{feat}_lag{lag}'] = df.groupby('region', sort=False)[feat].shift(lag)\n",
    "    \n",
    "    # Create rolling aggregations (3 and 6 periods) with shift(1) to prevent leakage\n",
    "    # These capture trends and momentum\n",
    "    print(\"Creating rolling window features (3 and 6 periods)...\")\n",
    "    for feat in key_gdelt_features:\n",
    "        for window in [3, 6]:\n",
    "            df[f'{feat}_rolling_{window}'] = (\n",
    "                df.groupby('region', sort=False)[feat]\n",
    "                .shift(1).rolling(window, min_periods=1).mean()\n",
    "            )\n",
    "    \n",
    "    # Create anomaly features (deviation from historical mean)\n",
    "    # These capture unusual spikes or drops\n",
    "    print(\"Creating anomaly features (deviation from historical mean)...\")\n",
    "    for feat in key_gdelt_features:\n",
    "        historical_mean = df.groupby('region', sort=False)[feat].transform(\n",
    "            lambda x: x.expanding().mean().shift(1)\n",
    "        )\n",
    "        df[f'{feat}_anomaly'] = df[feat] - historical_mean\n",
    "    \n",
    "    # Create escalation features (short-term vs medium-term trend)\n",
    "    # Positive escalation = accelerating crisis\n",
    "    print(\"Creating escalation features (short-term vs medium-term)...\")\n",
    "    for feat in key_gdelt_features:\n",
    "        if f'{feat}_rolling_3' in df.columns and f'{feat}_rolling_6' in df.columns:\n",
    "            df[f'{feat}_escalation'] = (\n",
    "                df[f'{feat}_rolling_3'] - df[f'{feat}_rolling_6']\n",
    "            )\n",
    "    \n",
    "    # Create change features (period-over-period change)\n",
    "    print(\"Creating change features (period-over-period change)...\")\n",
    "    for feat in key_gdelt_features:\n",
    "        df[f'{feat}_change'] = df.groupby('region', sort=False)[feat].diff(1)\n",
    "        df[f'{feat}_change_pct'] = df.groupby('region', sort=False)[feat].pct_change(1, fill_method=None)\n",
    "    \n",
    "    temporal_features_count = len([c for c in df.columns if any(x in c for x in ['_lag', '_rolling', '_anomaly', '_escalation', '_change'])])\n",
    "    print(f\"\\nCreated {temporal_features_count} temporal GDELT features\")\n",
    "    print(\"These features capture:\")\n",
    "    print(\"  - Historical patterns (lags)\")\n",
    "    print(\"  - Trends (rolling windows)\")\n",
    "    print(\"  - Anomalies (deviations from mean)\")\n",
    "    print(\"  - Escalation (acceleration patterns)\")\n",
    "    print(\"  - Changes (period-over-period dynamics)\")\n",
    "else:\n",
    "    print(\"Warning: No key GDELT features found. Using only current-period GDELT features.\")\n",
    "\n",
    "print(f\"\\nDataFrame shape after temporal GDELT features: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Baseline Models (matching previous work framework)\n",
    "# ===========================================================\n",
    "# Implement the 4 baseline models from 6_modelling_conflicts_lags.ipynb:\n",
    "# 1. PPS (Previous Period Same)\n",
    "# 2. SPLY (Same Period Last Year)\n",
    "# 3. Max-2PP (Max of Previous 2 Periods)\n",
    "# 4. ML Baseline (Logistic Regression, Random Forest, CatBoost with only geographic + temporal features)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== Step 7: Baseline Models (No GDELT Features) ===\\n\")\n",
    "\n",
    "# Store baseline results\n",
    "base_summary = pd.DataFrame(columns=['Model', 'Test Accuracy', 'Test Precision', 'Test Recall', 'F1'])\n",
    "\n",
    "# ============================================================\n",
    "# Baseline 1: PPS (Previous Period Same)\n",
    "# ============================================================\n",
    "print(\"1. PPS (Previous Period Same)...\")\n",
    "train_pps = train[train['period'].isin(sorted(train['period'].unique())[-1:])][['ADMIN0', 'ADMIN1', 'ADMIN2', 'CS_score', 'period']].copy()\n",
    "train_pps = train_pps.rename(columns={'CS_score': 'predicted'})\n",
    "test_pps = test.merge(train_pps[['ADMIN0', 'ADMIN1', 'ADMIN2', 'predicted']], \n",
    "                      on=['ADMIN0', 'ADMIN1', 'ADMIN2'], how='left')\n",
    "test_pps['predicted'] = test_pps['predicted'].fillna(0).astype(int)\n",
    "\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'PPS',\n",
    "    accuracy_score(test_pps['CS_score'], test_pps['predicted']),\n",
    "    precision_score(test_pps['CS_score'], test_pps['predicted'], average='weighted', zero_division=0),\n",
    "    recall_score(test_pps['CS_score'], test_pps['predicted'], average='weighted', zero_division=0),\n",
    "    f1_score(test_pps['CS_score'], test_pps['predicted'], average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Baseline 2: SPLY (Same Period Last Year)\n",
    "# ============================================================\n",
    "print(\"2. SPLY (Same Period Last Year)...\")\n",
    "current_period = test['period'].max()\n",
    "last_year_num = int(str(current_period)) - 100\n",
    "try:\n",
    "    last_year = type(current_period)(last_year_num)\n",
    "except Exception:\n",
    "    last_year = str(last_year_num)\n",
    "\n",
    "train_sply = train[train['period'] == last_year][['ADMIN0', 'ADMIN1', 'ADMIN2', 'CS_score', 'period']].copy()\n",
    "if len(train_sply) > 0:\n",
    "    train_sply = train_sply.rename(columns={'CS_score': 'predicted'})\n",
    "    test_sply = test.merge(train_sply[['ADMIN0', 'ADMIN1', 'ADMIN2', 'predicted']], \n",
    "                          on=['ADMIN0', 'ADMIN1', 'ADMIN2'], how='left')\n",
    "    test_sply['predicted'] = test_sply['predicted'].fillna(0).astype(int)\n",
    "    \n",
    "    base_summary.loc[len(base_summary)] = [\n",
    "        'SPLY',\n",
    "        accuracy_score(test_sply['CS_score'], test_sply['predicted']),\n",
    "        precision_score(test_sply['CS_score'], test_sply['predicted'], average='weighted', zero_division=0),\n",
    "        recall_score(test_sply['CS_score'], test_sply['predicted'], average='weighted', zero_division=0),\n",
    "        f1_score(test_sply['CS_score'], test_sply['predicted'], average='weighted', zero_division=0)\n",
    "    ]\n",
    "else:\n",
    "    print(f\"   Warning: No data for period {last_year}, skipping SPLY\")\n",
    "\n",
    "# ============================================================\n",
    "# Baseline 3: Max-2PP (Max of Previous 2 Periods)\n",
    "# ============================================================\n",
    "print(\"3. Max-2PP (Max of Previous 2 Periods)...\")\n",
    "train_m2 = train[train['period'].isin(sorted(train['period'].unique())[-2:])][['ADMIN0', 'ADMIN1', 'ADMIN2', 'CS_score']].copy()\n",
    "train_m2 = train_m2.groupby(['ADMIN0', 'ADMIN1', 'ADMIN2'])['CS_score'].max().reset_index()\n",
    "train_m2 = train_m2.rename(columns={'CS_score': 'predicted'})\n",
    "test_m2 = test.merge(train_m2, on=['ADMIN0', 'ADMIN1', 'ADMIN2'], how='left')\n",
    "test_m2['predicted'] = test_m2['predicted'].fillna(0).astype(int)\n",
    "\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'Max-2PP',\n",
    "    accuracy_score(test_m2['CS_score'], test_m2['predicted']),\n",
    "    precision_score(test_m2['CS_score'], test_m2['predicted'], average='weighted', zero_division=0),\n",
    "    recall_score(test_m2['CS_score'], test_m2['predicted'], average='weighted', zero_division=0),\n",
    "    f1_score(test_m2['CS_score'], test_m2['predicted'], average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Baseline 4: ML Models (only geographic + temporal features)\n",
    "# ============================================================\n",
    "print(\"4. ML Baseline Models (Geographic + Temporal features only)...\")\n",
    "\n",
    "# Prepare features: only previous_CS, transitions_prev, and one-hot encoded geography\n",
    "use_features = [\n",
    "    'region', 'district', 'period', 'CS_score', 'ADMIN0',\n",
    "    'previous_CS',\n",
    "    'transitions_prev'\n",
    "]\n",
    "\n",
    "train_ml = train[use_features].copy()\n",
    "test_ml = test[use_features].copy()\n",
    "\n",
    "# One-hot encode geography\n",
    "train_ml = pd.get_dummies(train_ml, columns=['region', 'district', 'ADMIN0'], dtype=int)\n",
    "test_ml = pd.get_dummies(test_ml, columns=['region', 'district', 'ADMIN0'], dtype=int)\n",
    "\n",
    "# Align dummy columns\n",
    "train_ml, test_ml = train_ml.align(test_ml, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Prepare feature matrix\n",
    "cols = list(train_ml.columns)\n",
    "cols.remove('CS_score')\n",
    "cols.remove('period')\n",
    "\n",
    "X_baseline = train_ml[cols].copy()\n",
    "y_baseline = train_ml['CS_score'].copy()\n",
    "X_test_baseline = test_ml[cols].copy()\n",
    "y_test_baseline = test_ml['CS_score'].copy()\n",
    "\n",
    "print(f\"   Baseline features: {len(cols)} (geographic dummies + previous_CS + transitions_prev)\")\n",
    "\n",
    "# Train models\n",
    "print(\"   Training Logistic Regression...\")\n",
    "LR_model = LogisticRegression(class_weight='balanced', random_state=5).fit(X_baseline, y_baseline)\n",
    "preds_lr = LR_model.predict(X_test_baseline)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'LogisticRegression(class_weight=\\'balanced\\', random_state=5)',\n",
    "    accuracy_score(y_test_baseline, preds_lr),\n",
    "    precision_score(y_test_baseline, preds_lr, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_baseline, preds_lr, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_baseline, preds_lr, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "print(\"   Training Random Forest...\")\n",
    "RF_model = RandomForestClassifier(\n",
    "    n_estimators=200, min_samples_split=10,\n",
    "    class_weight='balanced', n_jobs=-1, random_state=5\n",
    ").fit(X_baseline, y_baseline)\n",
    "preds_rf = RF_model.predict(X_test_baseline)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'RandomForestClassifier(class_weight=\\'balanced\\', min_samples_split=10, n_estimators=200, n_jobs=-1, random_state=5)',\n",
    "    accuracy_score(y_test_baseline, preds_rf),\n",
    "    precision_score(y_test_baseline, preds_rf, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_baseline, preds_rf, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_baseline, preds_rf, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "print(\"   Training CatBoost...\")\n",
    "Cat_model = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=[1, 1, 1, 1],\n",
    "    random_seed=5,\n",
    "    verbose=False\n",
    ").fit(X_baseline, y_baseline)\n",
    "preds_cat = Cat_model.predict(X_test_baseline)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    '<catboost.core.CatBoostClassifier object>',\n",
    "    accuracy_score(y_test_baseline, preds_cat),\n",
    "    precision_score(y_test_baseline, preds_cat, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_baseline, preds_cat, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_baseline, preds_cat, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "print(\"\\n=== BASELINE MODEL RESULTS (No GDELT Features) ===\")\n",
    "print(base_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Adding GDELT Features and Comparing with Baseline\n",
    "# =========================================================\n",
    "# Goal: Show that GDELT/NLP features add predictive value beyond temporal/geographic patterns\n",
    "# Matching the framework from previous work (adding conflict features -> adding GDELT features)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== Step 8: Adding GDELT Features ===\\n\")\n",
    "\n",
    "# Prepare features: baseline features + GDELT features\n",
    "use_features_full = [\n",
    "    'region', 'district', 'period', 'CS_score', 'ADMIN0',\n",
    "    'previous_CS',\n",
    "    'transitions_prev'\n",
    "]\n",
    "\n",
    "# Add all GDELT features (evt_* and gkg_* aggregated features)\n",
    "gdelt_features = [c for c in train.columns if c.startswith('evt_') or c.startswith('gkg_')]\n",
    "use_features_full.extend(gdelt_features)\n",
    "\n",
    "# Keep only features that exist\n",
    "use_features_full = [f for f in use_features_full if f in train.columns]\n",
    "\n",
    "train_full = train[use_features_full].copy()\n",
    "test_full = test[use_features_full].copy()\n",
    "\n",
    "# One-hot encode geography\n",
    "train_full = pd.get_dummies(train_full, columns=['region', 'district', 'ADMIN0'], dtype=int)\n",
    "test_full = pd.get_dummies(test_full, columns=['region', 'district', 'ADMIN0'], dtype=int)\n",
    "\n",
    "# Align dummy columns\n",
    "train_full, test_full = train_full.align(test_full, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Prepare feature matrix\n",
    "cols_full = list(train_full.columns)\n",
    "cols_full.remove('CS_score')\n",
    "cols_full.remove('period')\n",
    "\n",
    "X_full = train_full[cols_full].copy()\n",
    "y_full = train_full['CS_score'].copy()\n",
    "X_test_full = test_full[cols_full].copy()\n",
    "y_test_full = test_full['CS_score'].copy()\n",
    "\n",
    "print(f\"Baseline features: {len(X_baseline.columns)} (geographic dummies + previous_CS + transitions_prev)\")\n",
    "print(f\"Full model features: {len(cols_full)} (baseline + {len(gdelt_features)} GDELT features)\\n\")\n",
    "\n",
    "# Handle missing values in GDELT features (fill with 0 for missing GDELT data)\n",
    "X_full = X_full.fillna(0)\n",
    "X_test_full = X_test_full.fillna(0)\n",
    "\n",
    "# Train same models with GDELT features\n",
    "print(\"Training models with GDELT features...\")\n",
    "\n",
    "print(\"   Training Logistic Regression with GDELT...\")\n",
    "LR_model_full = LogisticRegression(class_weight='balanced', random_state=5).fit(X_full, y_full)\n",
    "preds_lr_full = LR_model_full.predict(X_test_full)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'LogisticRegression (with GDELT)',\n",
    "    accuracy_score(y_test_full, preds_lr_full),\n",
    "    precision_score(y_test_full, preds_lr_full, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_full, preds_lr_full, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_full, preds_lr_full, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "print(\"   Training Random Forest with GDELT...\")\n",
    "RF_model_full = RandomForestClassifier(\n",
    "    n_estimators=200, min_samples_split=10,\n",
    "    class_weight='balanced', n_jobs=-1, random_state=5\n",
    ").fit(X_full, y_full)\n",
    "preds_rf_full = RF_model_full.predict(X_test_full)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'RandomForestClassifier (with GDELT)',\n",
    "    accuracy_score(y_test_full, preds_rf_full),\n",
    "    precision_score(y_test_full, preds_rf_full, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_full, preds_rf_full, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_full, preds_rf_full, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "print(\"   Training CatBoost with GDELT...\")\n",
    "Cat_model_full = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=[1, 1, 1, 1],\n",
    "    random_seed=5,\n",
    "    verbose=False\n",
    ").fit(X_full, y_full)\n",
    "preds_cat_full = Cat_model_full.predict(X_test_full)\n",
    "base_summary.loc[len(base_summary)] = [\n",
    "    'CatBoostClassifier (with GDELT)',\n",
    "    accuracy_score(y_test_full, preds_cat_full),\n",
    "    precision_score(y_test_full, preds_cat_full, average='weighted', zero_division=0),\n",
    "    recall_score(y_test_full, preds_cat_full, average='weighted', zero_division=0),\n",
    "    f1_score(y_test_full, preds_cat_full, average='weighted', zero_division=0)\n",
    "]\n",
    "\n",
    "# Print final comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL COMPARISON: Baseline vs Baseline + GDELT Features\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\" + base_summary.to_string(index=False))\n",
    "\n",
    "# Calculate improvements for ML models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compare each ML model baseline vs with GDELT\n",
    "lr_baseline_acc = base_summary[base_summary['Model'].str.contains('LogisticRegression') & ~base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "lr_full_acc = base_summary[base_summary['Model'].str.contains('LogisticRegression') & base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "\n",
    "rf_baseline_acc = base_summary[base_summary['Model'].str.contains('RandomForestClassifier') & ~base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "rf_full_acc = base_summary[base_summary['Model'].str.contains('RandomForestClassifier') & base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "\n",
    "cat_baseline_acc = base_summary[base_summary['Model'].str.contains('CatBoost') & ~base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "cat_full_acc = base_summary[base_summary['Model'].str.contains('CatBoost') & base_summary['Model'].str.contains('GDELT')]['Test Accuracy'].values[0]\n",
    "\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"  Baseline: {lr_baseline_acc:.4f} → With GDELT: {lr_full_acc:.4f} (Δ {lr_full_acc - lr_baseline_acc:+.4f})\")\n",
    "\n",
    "print(f\"\\nRandom Forest:\")\n",
    "print(f\"  Baseline: {rf_baseline_acc:.4f} → With GDELT: {rf_full_acc:.4f} (Δ {rf_full_acc - rf_baseline_acc:+.4f})\")\n",
    "\n",
    "print(f\"\\nCatBoost:\")\n",
    "print(f\"  Baseline: {cat_baseline_acc:.4f} → With GDELT: {cat_full_acc:.4f} (Δ {cat_full_acc - cat_baseline_acc:+.4f})\")\n",
    "\n",
    "if rf_full_acc > rf_baseline_acc or cat_full_acc > cat_baseline_acc:\n",
    "    print(\"\\n✓ SUCCESS: GDELT features add predictive value!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Note: GDELT features do not improve performance significantly\")\n",
    "    print(\"   This suggests GDELT features may not add predictive value beyond\")\n",
    "    print(\"   geographic and temporal patterns, similar to conflict features in previous work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance and Confusion Matrices\n",
    "# ==========================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE AND CONFUSION MATRICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Feature Importance from Random Forest Baseline\n",
    "print(\"\\n=== Top 20 Features by Importance (Random Forest Baseline) ===\")\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_baseline.columns,\n",
    "    'Importance': RF_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(rf_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Feature Importance from Random Forest Full (with GDELT)\n",
    "print(\"\\n=== Top 20 Features by Importance (Random Forest with GDELT) ===\")\n",
    "rf_full_importance = pd.DataFrame({\n",
    "    'Feature': X_full.columns,\n",
    "    'Importance': RF_model_full.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(rf_full_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Top GDELT features\n",
    "print(\"\\n=== Top 20 GDELT Features by Importance ===\")\n",
    "gdelt_importance = rf_full_importance[rf_full_importance['Feature'].str.startswith(('evt_', 'gkg_'))].head(20)\n",
    "print(gdelt_importance.to_string(index=False))\n",
    "\n",
    "# Confusion Matrices\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n=== Random Forest Baseline ===\")\n",
    "cm_baseline = confusion_matrix(y_test_baseline, preds_rf, labels=[1, 2, 3, 4, 5])\n",
    "print(cm_baseline)\n",
    "print(f\"\\nPredicted classes: {sorted(np.unique(preds_rf))}\")\n",
    "print(f\"Actual classes: {sorted(np.unique(y_test_baseline))}\")\n",
    "\n",
    "print(\"\\n=== Random Forest with GDELT ===\")\n",
    "cm_full = confusion_matrix(y_test_full, preds_rf_full, labels=[1, 2, 3, 4, 5])\n",
    "print(cm_full)\n",
    "print(f\"\\nPredicted classes: {sorted(np.unique(preds_rf_full))}\")\n",
    "print(f\"Actual classes: {sorted(np.unique(y_test_full))}\")\n",
    "\n",
    "# Visualize confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Baseline confusion matrix\n",
    "cm_baseline_percent = cm_baseline / cm_baseline.sum() * 100\n",
    "sns.heatmap(cm_baseline_percent, annot=True, fmt='.1f', cmap='Blues', \n",
    "            xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5],\n",
    "            ax=axes[0], cbar_kws={'label': 'Percentage'})\n",
    "axes[0].set_title('Random Forest Baseline\\n(Geographic + Temporal)', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Full model confusion matrix\n",
    "cm_full_percent = cm_full / cm_full.sum() * 100\n",
    "sns.heatmap(cm_full_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "            xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5],\n",
    "            ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "axes[1].set_title('Random Forest with GDELT\\n(Baseline + GDELT Features)', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Literature Shows Better Results: Key Differences\n",
    "\n",
    "## Potential Reasons for Better Performance in Literature:\n",
    "\n",
    "1. **Different Prediction Tasks**:\n",
    "   - **Transitions/Changes**: Predicting when CS_score will worsen (crisis onset) rather than exact level\n",
    "   - **Early Warning**: Predicting 2-4 periods ahead (forecasting) rather than next period (nowcasting)\n",
    "   - **Binary Classification**: Predicting crisis (CS≥3) vs non-crisis (CS<3) rather than 5-class classification\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - **Temporal Patterns**: Using lagged and rolling features (as we just added) rather than only current-period values\n",
    "   - **Anomaly Detection**: Focusing on deviations from historical patterns\n",
    "   - **Interaction Features**: Combining GDELT with other data sources (weather, prices, etc.)\n",
    "\n",
    "3. **Data Coverage**:\n",
    "   - **Spatial Aggregation**: Some studies aggregate to ADMIN0 or ADMIN1 level where coverage is better\n",
    "   - **Temporal Aggregation**: Using quarterly rather than monthly data\n",
    "   - **Filtering**: Focusing on regions/periods with good GDELT coverage\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - **Recall for Rare Events**: Focusing on detecting crises (high recall for CS≥3) rather than overall accuracy\n",
    "   - **Early Detection**: Measuring how early they detect transitions, not just accuracy\n",
    "\n",
    "5. **Baseline Comparison**:\n",
    "   - **Weaker Baselines**: Some studies don't include `previous_CS` in baseline, making improvement easier to show\n",
    "   - **Different Baselines**: Comparing against simpler models or using different evaluation windows\n",
    "\n",
    "## Our Current Approach:\n",
    "- ✅ Now includes temporal GDELT features (lags, rolling windows, anomalies, escalation)\n",
    "- ✅ Uses same framework as previous work (allowing fair comparison)\n",
    "- ⚠️ Still predicting exact CS_score level (highly autocorrelated)\n",
    "- ⚠️ Using monthly data with CS_score available every 4 months\n",
    "\n",
    "## Potential Improvements:\n",
    "1. **Predict Transitions**: Predict if CS_score will worsen (CS_t+1 > CS_t) rather than exact value\n",
    "2. **Forecasting Horizon**: Predict 2-4 periods ahead instead of next period\n",
    "3. **Crisis Detection**: Binary classification (crisis vs non-crisis) with focus on recall\n",
    "4. **Feature Selection**: Use only temporal GDELT features, filter out low-importance current-period features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: XGBoost Models (matching previous work framework)\n",
    "# ============================================================\n",
    "# Optional additional model comparison using XGBoost\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=== Optional: XGBoost Models ===\\n\")\n",
    "    \n",
    "    # XGBoost requires labels to start from 0, so map 1-5 to 0-4\n",
    "    label_mapping = {cls: idx for idx, cls in enumerate(sorted(y_baseline.unique()))}\n",
    "    reverse_mapping = {idx: cls for cls, idx in label_mapping.items()}\n",
    "    \n",
    "    y_baseline_mapped = y_baseline.map(label_mapping)\n",
    "    y_test_baseline_mapped = y_test_baseline.map(label_mapping)\n",
    "    y_full_mapped = y_full.map(label_mapping)\n",
    "    y_test_full_mapped = y_test_full.map(label_mapping)\n",
    "    \n",
    "    # XGBoost Baseline\n",
    "    print(\"Training XGBoost Baseline Model...\")\n",
    "    xgb_baseline = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        random_state=5,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb_baseline.fit(X_baseline, y_baseline_mapped)\n",
    "    preds_xgb_baseline_mapped = xgb_baseline.predict(X_test_baseline)\n",
    "    preds_xgb_baseline = pd.Series(preds_xgb_baseline_mapped).map(reverse_mapping).values\n",
    "    \n",
    "    xgb_baseline_acc = accuracy_score(y_test_baseline, preds_xgb_baseline)\n",
    "    xgb_baseline_prec = precision_score(y_test_baseline, preds_xgb_baseline, average='weighted', zero_division=0)\n",
    "    xgb_baseline_rec = recall_score(y_test_baseline, preds_xgb_baseline, average='weighted', zero_division=0)\n",
    "    xgb_baseline_f1 = f1_score(y_test_baseline, preds_xgb_baseline, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Add to summary\n",
    "    base_summary.loc[len(base_summary)] = [\n",
    "        'XGBoostClassifier (baseline)',\n",
    "        xgb_baseline_acc,\n",
    "        xgb_baseline_prec,\n",
    "        xgb_baseline_rec,\n",
    "        xgb_baseline_f1\n",
    "    ]\n",
    "    \n",
    "    # XGBoost Full (with GDELT)\n",
    "    print(\"Training XGBoost Full Model (with GDELT)...\")\n",
    "    xgb_full = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        random_state=5,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb_full.fit(X_full, y_full_mapped)\n",
    "    preds_xgb_full_mapped = xgb_full.predict(X_test_full)\n",
    "    preds_xgb_full = pd.Series(preds_xgb_full_mapped).map(reverse_mapping).values\n",
    "    \n",
    "    xgb_full_acc = accuracy_score(y_test_full, preds_xgb_full)\n",
    "    xgb_full_prec = precision_score(y_test_full, preds_xgb_full, average='weighted', zero_division=0)\n",
    "    xgb_full_rec = recall_score(y_test_full, preds_xgb_full, average='weighted', zero_division=0)\n",
    "    xgb_full_f1 = f1_score(y_test_full, preds_xgb_full, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Add to summary\n",
    "    base_summary.loc[len(base_summary)] = [\n",
    "        'XGBoostClassifier (with GDELT)',\n",
    "        xgb_full_acc,\n",
    "        xgb_full_prec,\n",
    "        xgb_full_rec,\n",
    "        xgb_full_f1\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"XGBOOST MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBaseline:\")\n",
    "    print(f\"  Accuracy: {xgb_baseline_acc:.4f}\")\n",
    "    print(f\"  F1:       {xgb_baseline_f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nWith GDELT:\")\n",
    "    print(f\"  Accuracy: {xgb_full_acc:.4f}\")\n",
    "    print(f\"  F1:       {xgb_full_f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nImprovement:\")\n",
    "    print(f\"  Accuracy: {xgb_full_acc - xgb_baseline_acc:+.4f}\")\n",
    "    print(f\"  F1:       {xgb_full_f1 - xgb_baseline_f1:+.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"UPDATED FINAL MODEL COMPARISON (Including XGBoost)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n\" + base_summary.to_string(index=False))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "    print(\"Skipping XGBoost models.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with XGBoost models: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"Skipping XGBoost models.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary\n",
    "\n",
    "### Features Created:\n",
    "\n",
    "1. **List Aggregations** (from both events and gkg):\n",
    "   - Mean, Max, Min, Sum, Count, Std for all list features\n",
    "   - Separated by `evt_` and `gkg_` prefixes\n",
    "\n",
    "2. **Combined Features**:\n",
    "   - CS_score combinations (combined, diff, has_both)\n",
    "   - Casualty rates and totals\n",
    "   - Theme aggregations (conflict intensity, crisis severity)\n",
    "   - Sentiment combinations\n",
    "   - Coverage intensity metrics\n",
    "\n",
    "3. **Temporal Features**:\n",
    "   - Lag features (CS_score_lag1, lag2, lag3)\n",
    "   - Moving averages (ma2, ma3)\n",
    "   - Change and percentage change features\n",
    "   - Cyclical period encoding (sin/cos)\n",
    "\n",
    "4. **Geographic Features**:\n",
    "   - Aggregated CS_score by ADMIN0 and ADMIN1 levels\n",
    "   - Standard deviations by geographic level\n",
    "   - Count of regions with same score\n",
    "\n",
    "5. **Interaction Features**:\n",
    "   - Ratios (casualty_rate, aid_per_casualty)\n",
    "   - Normalized features (tone_abs_normalized)\n",
    "   - Coverage metrics (mentions_per_source, articles_per_source)\n",
    "\n",
    "### Next Steps for ML:\n",
    "\n",
    "1. **Feature Selection**: Consider using:\n",
    "   - Correlation-based selection\n",
    "   - Mutual information\n",
    "   - Recursive feature elimination\n",
    "   - L1 regularization (Lasso)\n",
    "\n",
    "2. **Categorical Encoding**: If you have categorical features:\n",
    "   - One-hot encoding for low cardinality\n",
    "   - Target encoding for high cardinality\n",
    "   - Embedding for very high cardinality\n",
    "\n",
    "3. **Scaling**: Consider:\n",
    "   - StandardScaler or MinMaxScaler for numeric features\n",
    "   - Especially important for distance-based algorithms\n",
    "\n",
    "4. **Model Suggestions**:\n",
    "   - Random Forest (handles non-linear relationships well)\n",
    "   - Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "   - Neural Networks (if you have enough data)\n",
    "   - Consider class weights if classes are imbalanced\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
