{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a Bert model to identify specific topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from transformers import (\n",
    "    BertModel, BertTokenizer, BertPreTrainedModel,\n",
    "    DataCollatorWithPadding, TrainingArguments, Trainer\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 0.  DEVICE\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "device = torch.device(\"mps\")  # Apple‑silicon GPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  MULTI‑TASK MODEL\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "class MultiTaskBERT(BertPreTrainedModel):\n",
    "    \"\"\"BERT backbone + 3 classification heads (impact, urgency, resources).\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_impact: int, num_urgency: int, num_resource: int):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.impact_head = nn.Linear(config.hidden_size, num_impact)\n",
    "        self.urgency_head = nn.Linear(config.hidden_size, num_urgency)\n",
    "        self.resource_head = nn.Linear(config.hidden_size, num_resource)\n",
    "        self.init_weights()\n",
    "\n",
    "    # **kwargs swallows any extra keys Trainer might pass (impact_type_id …)\n",
    "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
    "        pooled = self.dropout(self.bert(input_ids, attention_mask).pooler_output)\n",
    "        return {\n",
    "            \"impact\":   self.impact_head(pooled),\n",
    "            \"urgency\":  self.urgency_head(pooled),\n",
    "            \"resource\": self.resource_head(pooled),\n",
    "        }\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  LOAD DATA & ENCODE LABELS\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "df_train = pd.read_pickle(\"./for_bert/expanded_train.pkl\")\n",
    "df_val   = pd.read_pickle(\"./for_bert/expanded_val.pkl\")\n",
    "\n",
    "impact_enc  = LabelEncoder()\n",
    "urgency_enc = LabelEncoder()\n",
    "\n",
    "df_train[\"impact_type_id\"] = impact_enc.fit_transform(df_train[\"impact_type\"])\n",
    "df_val[\"impact_type_id\"]   = impact_enc.transform(df_val[\"impact_type\"])\n",
    "\n",
    "df_train[\"urgency_id\"] = urgency_enc.fit_transform(df_train[\"urgency\"])\n",
    "df_val[\"urgency_id\"]   = urgency_enc.transform(df_val[\"urgency\"])\n",
    "\n",
    "resource_cols = [c for c in df_train.columns if c.startswith(\"resource_\")]\n",
    "\n",
    "cols = [\"input_ids\", \"impact_type_id\", \"urgency_id\"] + resource_cols\n",
    "\n",
    "# build HF datasets\n",
    "train_ds = Dataset.from_pandas(df_train[cols]).with_format(\"torch\")\n",
    "val_ds   = Dataset.from_pandas(df_val[cols]).with_format(\"torch\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3.  TOKENIZER & COLLATOR (dynamic padding)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "collator  = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 4.  BUILD MODEL (frozen backbone for quick test)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "model = MultiTaskBERT.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_impact=len(impact_enc.classes_),\n",
    "    num_urgency=len(urgency_enc.classes_),\n",
    "    num_resource=len(resource_cols),\n",
    ").to(device)\n",
    "\n",
    "for p in model.bert.parameters():  # comment out to fine‑tune full model\n",
    "    p.requires_grad = False\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 5.  CUSTOM TRAINER\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "class MultiTaskTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # move tensors to correct device\n",
    "        inputs = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in inputs.items()}\n",
    "\n",
    "        y_impact   = inputs.pop(\"impact_type_id\")\n",
    "        y_urgency  = inputs.pop(\"urgency_id\")\n",
    "        y_resource = torch.stack([inputs.pop(col) for col in resource_cols], dim=1).float()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "        )\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(outputs[\"impact\"],  y_impact)\n",
    "        loss += nn.CrossEntropyLoss()(outputs[\"urgency\"], y_urgency)\n",
    "        loss += nn.BCEWithLogitsLoss()(outputs[\"resource\"], y_resource)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 6.  TRAINING ARGS\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./bert_multitask_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,   #<- keep label columns\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 7.  TRAIN\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "trainer = MultiTaskTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 8.  SAVE MODEL\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "trainer.save_model(\"./for_bert/bert_multitask_model/final\")\n",
    "tokenizer.save_pretrained(\"./for_bert/bert_multitask_model/final\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
