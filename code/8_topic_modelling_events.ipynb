{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "- Train a specific BERT before using it\n",
    "- Add a step to use an LLM (probably LLnan3 locally) to add features, labels etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from helper_functions.topic_modelling.flatten_articles import flatten_articles\n",
    "from helper_functions.topic_modelling.sentiment_analysis import perform_sentiment_analysis\n",
    "from helper_functions.topic_modelling.add_counts_columns_parallel import (\n",
    "    add_synonym_frequency_columns,\n",
    "    add_category_count_columns\n",
    ")\n",
    "from helper_functions.topic_modelling.aggregate_articles import aggregate_articles, FS_CATEGORIES\n",
    "\n",
    "# 1️⃣ Load enriched event dataset with:\n",
    "#    - articles (list of cleaned + truncated text strings)\n",
    "#    - NER_admin0_list / admin1 / admin2\n",
    "#    - event metadata (ADMIN0/1/2, CS_score, period, etc.)\n",
    "# ================================================================\n",
    "\n",
    "exploded_df = pd.read_parquet(\"../data/gdelt/events/scraped_urls/cleaned_filtered_urls.parquet\")\n",
    "\n",
    "# ================================================================\n",
    "# 3️⃣ (OPTIONAL SAFETY) Ensure clean_text is string\n",
    "# ================================================================\n",
    "exploded_df[\"clean_text\"] = exploded_df[\"clean_text\"].astype(str)\n",
    "\n",
    "# ================================================================\n",
    "# 4️⃣ Sentiment Analysis\n",
    "# ================================================================\n",
    "exploded_df = perform_sentiment_analysis(exploded_df, text_col=\"clean_text\")\n",
    "print(\"Sentiment analysis done.\")\n",
    "\n",
    "# ================================================================\n",
    "# 5️⃣ Keyword frequency & category count features\n",
    "# ================================================================\n",
    "exploded_df = add_synonym_frequency_columns(exploded_df, text_col=\"clean_text\")\n",
    "print(\"Frequency counts done\")\n",
    "exploded_df = add_category_count_columns(exploded_df, text_col=\"clean_text\")\n",
    "print(\"Keyword & category counts added.\")\n",
    "\n",
    "# ================================================================\n",
    "# 6️⃣ Save in chunks\n",
    "# ================================================================\n",
    "out_dir = \"../data/gdelt/events/5_modelled\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "exploded_df.to_parquet(out_dir + \"/events_exploded_with_counts.parquet\", index=False)\n",
    "\n",
    "print(\"✅ Processing complete.\")\n",
    "exploded_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
